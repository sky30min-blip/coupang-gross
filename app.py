"""
ì¿ íŒ¡ê·¸ë¡œìŠ¤ ëŒ€ì‹œë³´ë“œ - ì›¹ì—ì„œ ë°ì´í„° í™•ì¸ ë° ì‘ì—… ì‹¤í–‰
ë°ì´í„° ê²€ì¦(Validation) ì‹œê°í™” í¬í•¨
"""

import os
import subprocess
import sys
from pathlib import Path
from typing import Any

import pandas as pd
import streamlit as st

try:
    import plotly.graph_objects as go
    HAS_PLOTLY = True
except ImportError:
    HAS_PLOTLY = False

st.set_page_config(
    page_title="ì¿ íŒ¡ê·¸ë¡œìŠ¤ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ›’",
    layout="wide",
)

# ë°ì´í„° íŒŒì¼ ê²½ë¡œ (ì ˆëŒ€ê²½ë¡œë¡œ ê³ ì •í•´ í•œê¸€ ê²½ë¡œ/í„°ë¯¸ë„ ì¸ì½”ë”© ë¬¸ì œ ì™„í™”)
BASE = Path(__file__).resolve().parent
TRENDING = BASE / "trending_keywords.csv"
NICHE_SCORE = BASE / "niche_score_report.csv"
NICHE_ANALYSIS = BASE / "niche_analysis.csv"
NICHE_TEST = BASE / "niche_test.csv"
FINAL_SOURCING = BASE / "final_sourcing_list.csv"
MARKET_CREDIBILITY = BASE / "market_credibility_report.csv"
SEASONAL_HUNTER = BASE / "seasonal_hunter_report.csv"
SEASONAL_CHARTS = BASE / "seasonal_charts"
NICHE_WITH_VOLUME = BASE / "niche_with_volume.csv"
TRENDING_WITH_VOLUME = BASE / "trending_with_volume.csv"
LIGHT_WEIGHT = BASE / "light_weight_niche.xlsx"
DB_PATH = BASE / "coupang_gross.db"
DEBUG_SCREENSHOTS = BASE / "debug_screenshots"
WHOLESALE_LOGIN_STATUS = BASE / "wholesale_login_status.json"


def _read_wholesale_login_status():
    if not WHOLESALE_LOGIN_STATUS.exists():
        return None
    try:
        import json
        with open(WHOLESALE_LOGIN_STATUS, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return None


def run_script(script_name: str, desc: str) -> tuple[str, int]:
    """Python ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰, (ì¶œë ¥í…ìŠ¤íŠ¸, ë¦¬í„´ì½”ë“œ) ë°˜í™˜. ë¡œê·¸ íŒŒì¼ì—ë„ ê¸°ë¡."""
    script_path = (BASE / script_name).resolve()
    if not script_path.exists():
        return f"ì˜¤ë¥˜: {script_name} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", 1
    env = {**os.environ, "PYTHONIOENCODING": "utf-8"}
    try:
        result = subprocess.run(
            [sys.executable, "-u", str(script_path)],
            cwd=str(BASE),
            capture_output=True,
            text=True,
            encoding="utf-8",
            errors="replace",
            timeout=3600,
            env=env,
        )
        out = (result.stdout or "") + (result.stderr or "")
        out_stripped = out.strip() or f"{desc} ì™„ë£Œ (ì¶œë ¥ ì—†ìŒ)"
        log_dir = BASE / "logs"
        log_dir.mkdir(parents=True, exist_ok=True)
        try:
            from datetime import datetime
            with open(log_dir / "dashboard_run.log", "a", encoding="utf-8") as f:
                f.write(f"\n=== {datetime.now().isoformat()} | {script_name} ===\n{out_stripped}\n")
        except Exception:
            pass
        return out_stripped, result.returncode
    except subprocess.TimeoutExpired:
        return "ì˜¤ë¥˜: ì‹¤í–‰ ì‹œê°„ ì´ˆê³¼ (1ì‹œê°„)", 1
    except Exception as e:
        return f"ì˜¤ë¥˜: {e}", 1


# ìƒë‹¨: ì œëª©(ì¢Œ) + ë„ë§¤ ë¡œê·¸ì¸ ì‹ í˜¸ë“±(ìš°)
_header_left, _header_right = st.columns([3, 1])
with _header_left:
    st.title("ğŸ›’ ì¿ íŒ¡ê·¸ë¡œìŠ¤ ëŒ€ì‹œë³´ë“œ")
    st.caption("ë„¤ì´ë²„ íŠ¸ë Œë“œ í‚¤ì›Œë“œ & ì¿ íŒ¡ ì‹œì¥ì„± ë¶„ì„ ê²°ê³¼")
with _header_right:
    _ls = _read_wholesale_login_status()
    _dg = _ls.get("domeggook") if _ls else None
    _oc = _ls.get("ownerclan") if _ls else None
    st.markdown("**ë„ë§¤ ë¡œê·¸ì¸**")
    if _dg is True:
        st.markdown("ğŸŸ¢ ë„ë§¤ê¾¹")
    elif _dg is False:
        st.markdown("ğŸ”´ ë„ë§¤ê¾¹")
    else:
        st.markdown("âšª ë„ë§¤ê¾¹")
    if _oc is True:
        st.markdown("ğŸŸ¢ ì˜¤ë„ˆí´ëœ")
    elif _oc is False:
        st.markdown("ğŸ”´ ì˜¤ë„ˆí´ëœ")
    else:
        st.markdown("âšª ì˜¤ë„ˆí´ëœ")
    if st.button("ìƒíƒœ í™•ì¸", key="btn_wholesale_check", help="ë¡œê·¸ì¸ë§Œ ì‹œë„ í›„ ì‹ í˜¸ë“± ê°±ì‹ "):
        with st.spinner("í™•ì¸ ì¤‘..."):
            run_script("check_wholesale_login.py", "ë¡œê·¸ì¸ ìƒíƒœ í™•ì¸")
        st.rerun()


def _style_rocket_zero(df: pd.DataFrame, rocket_col: str = "rocket_count") -> Any:
    """ë¡œì¼“ìˆ˜ 0ì¸ í–‰ ì£¼í™©ìƒ‰ ê°•ì¡°"""
    if rocket_col not in df.columns:
        return df.style
    def _row_style(row):
        try:
            rc = row.get(rocket_col)
            if rc is not None and (rc == 0 or rc == "0"):
                return ["background-color: #ffcc80"] * len(row)
        except Exception:
            pass
        return [""] * len(row)
    return df.style.apply(_row_style, axis=1)


def _add_validation_icon(df: pd.DataFrame, rocket_col: str = "rocket_count", vcol: str = "verification_needed") -> pd.DataFrame:
    """ë¡œì¼“ìˆ˜ 0 ë˜ëŠ” verification_needed=Yì¸ í–‰ì— ìˆ˜ë™ ê²€ì¦ í•„ìš” ì•„ì´ì½˜ ì¶”ê°€"""
    df = df.copy()
    if "_validation" not in df.columns:
        df["_validation"] = ""
    def _need(r):
        if str(r.get(vcol, "")).upper() == "Y":
            return "âš ï¸ ìˆ˜ë™ ê²€ì¦ í•„ìš”"
        if rocket_col in df.columns and r.get(rocket_col) is not None and r.get(rocket_col) == 0:
            return "âš ï¸ ìˆ˜ë™ ê²€ì¦ í•„ìš”"
        return ""
    df["_validation"] = df.apply(_need, axis=1)
    return df


# === ì‘ì—… ì‹¤í–‰ íŒ¨ë„ (ìƒë‹¨) ===
st.subheader("ğŸš€ ì‘ì—… ì‹¤í–‰")
st.markdown("ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ê° ì‘ì—…ì„ ì‹¤í–‰í•˜ì„¸ìš”. ì‹¤í–‰ í›„ í•´ë‹¹ íƒ­ì—ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

col1, col2, col3, col4, col5, col6, col7, col8, col9, col10 = st.columns(10)

with col1:
    if st.button(
        "ğŸ“¥ ë„¤ì´ë²„ íŠ¸ë Œë“œ ìŠ¤í¬ë˜í•‘",
        key="btn_scraper",
        help="ë„¤ì´ë²„ ë°ì´í„°ë© ì‡¼í•‘ ì¸ì‚¬ì´íŠ¸ì—ì„œ ìµœê·¼ 1ì£¼ì¼ ì¸ê¸° ê²€ìƒ‰ì–´ë¥¼ ìˆ˜ì§‘í•˜ì—¬ trending_keywords.csvì— ì €ì¥í•©ë‹ˆë‹¤. ì´í›„ ì¿ íŒ¡ ë¶„ì„ ì‘ì—…ì˜ ì…ë ¥ ë°ì´í„°ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.",
        use_container_width=True,
    ):
        with st.spinner("ìŠ¤í¬ë˜í•‘ ì‹¤í–‰ ì¤‘... (1~2ë¶„ ì†Œìš”)"):
            out, code = run_script("naver_shopping_insight_scraper.py", "ë„¤ì´ë²„ íŠ¸ë Œë“œ ìŠ¤í¬ë˜í•‘")
        st.session_state["last_output"] = out
        st.session_state["last_code"] = code

with col2:
    if st.button(
        "ğŸ“ˆ ì¿ íŒ¡ ì‹œì¥ì„± ë¶„ì„",
        key="btn_analyzer",
        help="trending_keywords.csvë¥¼ ì½ì–´ ì¿ íŒ¡ íŒŒíŠ¸ë„ˆìŠ¤ APIë¡œ ìƒí’ˆì„ ë¶„ì„í•˜ê³ , ì§„ì… ê°€ëŠ¥ì„± ì ìˆ˜(Opportunity Score)ë¥¼ ê³„ì‚°í•˜ì—¬ niche_score_report.csvì— ì €ì¥í•©ë‹ˆë‹¤. ìƒìœ„ 10ê°œ í‚¤ì›Œë“œë§Œ ë¶„ì„í•©ë‹ˆë‹¤.",
        use_container_width=True,
    ):
        with st.spinner("ì‹œì¥ì„± ë¶„ì„ ì‹¤í–‰ ì¤‘... (ì•½ 30ì´ˆ~1ë¶„ ì†Œìš”)"):
            out, code = run_script("coupang_analyzer.py", "ì¿ íŒ¡ ì‹œì¥ì„± ë¶„ì„")
        st.session_state["last_output"] = out
        st.session_state["last_code"] = code

with col3:
    if st.button(
        "ğŸ” ì¿ íŒ¡ ë‹ˆì¹˜ ë¶„ì„",
        key="btn_niche",
        help="trending_keywords.csvë¥¼ ì½ì–´ ì¿ íŒ¡ íŒŒíŠ¸ë„ˆìŠ¤ APIë¡œ ë¡œì¼“ë°°ì†¡ ìƒí’ˆ ìˆ˜, í‰ê· ê°€ê²©, S/A/B ë“±ê¸‰ì„ ë¶„ì„í•˜ì—¬ niche_analysis.csvì— ì €ì¥í•©ë‹ˆë‹¤. ìµœëŒ€ 50ê°œ í‚¤ì›Œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.",
        use_container_width=True,
    ):
        with st.spinner("ë‹ˆì¹˜ ë¶„ì„ ì‹¤í–‰ ì¤‘... (2~5ë¶„ ì†Œìš”, API ì œí•œ ì ìš©)"):
            out, code = run_script("niche_analysis.py", "ì¿ íŒ¡ ë‹ˆì¹˜ ë¶„ì„")
        st.session_state["last_output"] = out
        st.session_state["last_code"] = code

with col4:
    if st.button(
        "ğŸ§ª ë‹ˆì¹˜ í…ŒìŠ¤íŠ¸ (ìƒìœ„ 20ê°œ)",
        key="btn_niche_test",
        help="trending_keywords.csv ìƒìœ„ 20ê°œ í‚¤ì›Œë“œë§Œ ì¿ íŒ¡ì—ì„œ ë¶„ì„í•˜ì—¬ niche_test.csvì— ì €ì¥í•©ë‹ˆë‹¤. ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©ì…ë‹ˆë‹¤.",
        use_container_width=True,
    ):
        with st.spinner("ë‹ˆì¹˜ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘... (ì•½ 1ë¶„ ì†Œìš”)"):
            out, code = run_script("niche_test.py", "ë‹ˆì¹˜ í…ŒìŠ¤íŠ¸")
        st.session_state["last_output"] = out
        st.session_state["last_code"] = code

with col5:
    if st.button(
        "ğŸª ë„ë§¤ ê²€ìƒ‰ (ì†Œì‹± ë¦¬ìŠ¤íŠ¸)",
        key="btn_wholesale",
        help="niche_test.csvì˜ S/Aë“±ê¸‰ í‚¤ì›Œë“œë¥¼ ë„ë§¤ê¾¹Â·ì˜¤ë„ˆí´ëœì—ì„œ ê²€ìƒ‰í•˜ê³ , ê´‘ê³ ë¹„Â·ìˆ˜ìˆ˜ë£ŒÂ·ë°°ì†¡ë¹„Â·ë¶€ê°€ì„¸ ë°˜ì˜ í›„ ìµœì¢… ìˆœë§ˆì§„ 15% ì´ìƒë§Œ final_sourcing_list.csvë¡œ ì €ì¥í•©ë‹ˆë‹¤.",
        use_container_width=True,
    ):
        with st.spinner("ë„ë§¤ ê²€ìƒ‰ ì‹¤í–‰ ì¤‘... (5~15ë¶„ ì†Œìš”, í‚¤ì›Œë“œ ìˆ˜ì— ë”°ë¼)"):
            out, code = run_script("wholesale_searcher.py", "ë„ë§¤ ê²€ìƒ‰")
        st.session_state["last_output"] = out
        st.session_state["last_code"] = code

with col6:
    if st.button(
        "ğŸ“‹ ì‹ ë¢°ë„ ë¦¬í¬íŠ¸",
        key="btn_credibility",
        help="niche_test.csv í‚¤ì›Œë“œì— ëŒ€í•´ Naver DataLab APIë¡œ ê²€ìƒ‰ íŠ¸ë Œë“œ(1ë…„)ë¥¼ ìˆ˜ì§‘í•˜ê³ , ìˆ˜ìš”ì§‘ì¤‘ë„Â·ì‹œì¦Œì„±Â·ì•ˆì •ì„±Â·ë…ì ê°€ëŠ¥ì„±ì„ í‰ê°€í•˜ì—¬ market_credibility_report.csvë¡œ ì €ì¥í•©ë‹ˆë‹¤. ìƒìœ„ 5ê°œ ì¶”ì´ ê·¸ë˜í”„ ì´ë¯¸ì§€ ì €ì¥.",
        use_container_width=True,
    ):
        with st.spinner("ì‹ ë¢°ë„ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘... (1~2ë¶„ ì†Œìš”)"):
            out, code = run_script("market_credibility_report.py", "ì‹ ë¢°ë„ ë¦¬í¬íŠ¸")
        st.session_state["last_output"] = out
        st.session_state["last_code"] = code

with col7:
    if st.button(
        "ğŸ“¦ ì‚¬ì… ì í•©ì„± í•„í„°",
        key="btn_light",
        help="ê°€ê²© 1.5~6ë§Œì›, ë¶€í”¼ í° í’ˆëª© ì œì™¸, ë¬¶ìŒ(ì„¸íŠ¸/í‚¤íŠ¸/íŒ©) ê°€ì‚°ì  ì ìš© í›„ light_weight_niche.xlsx ì €ì¥",
        use_container_width=True,
    ):
        with st.spinner("ì‚¬ì… ì í•©ì„± í•„í„° ì ìš© ì¤‘..."):
            out, code = run_script("light_weight_filter.py", "ì‚¬ì… ì í•©ì„± í•„í„°")
        st.session_state["last_output"] = out
        st.session_state["last_code"] = code

with col8:
    if st.button(
        "ğŸ”„ ë§ˆìŠ¤í„° íŒŒì´í”„ë¼ì¸",
        key="btn_main",
        help="trending_keywords.csv â†’ Products DB â†’ ì¿ íŒ¡ ë¶„ì„ â†’ ì—…ë°ì´íŠ¸. ë¡œê·¸: logs/system.log",
        use_container_width=True,
    ):
        with st.spinner("ë§ˆìŠ¤í„° íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘... (2~5ë¶„)"):
            out, code = run_script("run_master.py", "ë§ˆìŠ¤í„° íŒŒì´í”„ë¼ì¸")
        st.session_state["last_output"] = out
        st.session_state["last_code"] = code

with col9:
    if st.button(
        "ğŸ“… ì‹œì¦Œ í—Œí„°",
        key="btn_seasonal",
        help="niche_test.csv í‚¤ì›Œë“œ 3ë…„ì¹˜ ì‹œì¦Œ íŒ¨í„´ ë¶„ì„. ë§¤ë…„ íŠ¹ì • ì›”ì— í­ë“±í•˜ëŠ” ë°˜ë³µ ì‹œì¦Œ í‚¤ì›Œë“œ ì¶”ì¶œ.",
        use_container_width=True,
    ):
        with st.spinner("ì‹œì¦Œ í—Œí„° ì‹¤í–‰ ì¤‘... (1~3ë¶„ ì†Œìš”)"):
            out, code = run_script("seasonal_analyzer.py", "ì‹œì¦Œ í—Œí„°")
        st.session_state["last_output"] = out
        st.session_state["last_code"] = code

with col10:
    if st.button(
        "ğŸ“Š ê²€ìƒ‰ëŸ‰ ìˆ˜ì§‘",
        key="btn_volume",
        help="niche_test.csv í‚¤ì›Œë“œì— ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  APIë¡œ ê²€ìƒ‰ëŸ‰ ì¶”ê°€ â†’ niche_with_volume.csv (ê²€ìƒ‰ëŸ‰â†‘ ë¡œì¼“â†“ ìˆœ)",
        use_container_width=True,
    ):
        with st.spinner("ê²€ìƒ‰ëŸ‰ ìˆ˜ì§‘ ì¤‘... (ì•½ 1~2ë¶„)"):
            out, code = run_script("naver_api_manager.py", "ê²€ìƒ‰ëŸ‰ ìˆ˜ì§‘")
        st.session_state["last_output"] = out
        st.session_state["last_code"] = code

if "last_output" in st.session_state:
    code = st.session_state.get("last_code", 0)
    st.divider()
    st.caption("ì‹¤í–‰ ê²°ê³¼")
    if code == 0:
        st.success("ì‹¤í–‰ ì™„ë£Œ")
    else:
        st.error("ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    st.code(st.session_state["last_output"], language="text")

st.divider()

# íƒ­ êµ¬ì„±
tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8, tab9, tab10, tab11 = st.tabs(
    ["ğŸ“Š íŠ¸ë Œë“œ", "ğŸ“ˆ ì‹œì¥ì„±", "ğŸ” ë‹ˆì¹˜", "ğŸ§ª ë‹ˆì¹˜í…ŒìŠ¤íŠ¸", "ğŸ“Š ê²€ìƒ‰ëŸ‰", "ğŸª ì†Œì‹±", "ğŸ“‹ ì‹ ë¢°ë„", "ğŸ“¦ ì‚¬ì…ì í•©", "ğŸ—„ï¸ DB", "ğŸ“… ì‹œì¦Œí—Œí„°", "ğŸ“‹ ìš”ì•½"]
)

# === íƒ­1: íŠ¸ë Œë“œ í‚¤ì›Œë“œ ===
with tab1:
    if TRENDING.exists():
        df = pd.read_csv(TRENDING, encoding="utf-8-sig")
        st.subheader("ë„¤ì´ë²„ ì‡¼í•‘ ì¸ì‚¬ì´íŠ¸ ì¸ê¸° ê²€ìƒ‰ì–´")
        st.write(f"ì´ **{len(df)}**ê°œ í‚¤ì›Œë“œ")
        col1, col2 = st.columns(2)
        with col1:
            cat_filter = st.multiselect("ì¹´í…Œê³ ë¦¬ í•„í„°", df["category"].unique().tolist(), default=df["category"].unique().tolist())
        with col2:
            search = st.text_input("í‚¤ì›Œë“œ ê²€ìƒ‰", placeholder="í‚¤ì›Œë“œ ì…ë ¥...")
        df_filtered = df[df["category"].isin(cat_filter)]
        if search:
            df_filtered = df_filtered[df_filtered["keyword"].str.contains(search, case=False, na=False)]
        col_map = {"category": "ì¹´í…Œê³ ë¦¬", "rank": "ìˆœìœ„", "keyword": "í‚¤ì›Œë“œ", "change_trend": "ë³€í™”ì¶”ì´"}
        st.dataframe(df_filtered.rename(columns=col_map), use_container_width=True, hide_index=True)
    else:
        st.warning("trending_keywords.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒë‹¨ 'ğŸ“¥ ë„¤ì´ë²„ íŠ¸ë Œë“œ ìŠ¤í¬ë˜í•‘' ë²„íŠ¼ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

# === íƒ­2: ì‹œì¥ì„± ì ìˆ˜ (coupang_analyzer ê²°ê³¼) ===
with tab2:
    if NICHE_SCORE.exists():
        df = pd.read_csv(NICHE_SCORE, encoding="utf-8-sig")
        st.subheader("ì¿ íŒ¡ ì§„ì… ê°€ëŠ¥ì„± ì ìˆ˜")
        st.write(f"ì´ **{len(df)}**ê°œ í‚¤ì›Œë“œ ë¶„ì„")

        # ìš”ì•½ ì¹´ë“œ
        c1, c2, c3, c4 = st.columns(4)
        with c1:
            st.metric("í‰ê·  ì ìˆ˜", f"{df['opportunity_score'].mean():.1f}")
        with c2:
            high = (df["opportunity_score"] >= 70).sum()
            st.metric("70ì  ì´ìƒ", f"{high}ê°œ")
        with c3:
            st.metric("í‰ê·  ë¡œì¼“ ìˆ˜", f"{df['rocket_count'].mean():.1f}")
        with c4:
            st.metric("í‰ê·  ê°€ê²©ëŒ€", f"{df['avg_price'].mean():,.0f}ì›")

        # ì ìˆ˜ìˆœ ì •ë ¬
        score_min = st.slider("ìµœì†Œ ì§„ì…ì ìˆ˜", 0, 100, 0)
        df_filtered = df[df["opportunity_score"] >= score_min].sort_values("opportunity_score", ascending=False)
        col_map = {
            "category": "ì¹´í…Œê³ ë¦¬", "rank": "ìˆœìœ„", "keyword": "í‚¤ì›Œë“œ", "change_trend": "ë³€í™”ì¶”ì´",
            "rocket_count": "ë¡œì¼“ìˆ˜", "avg_price": "í‰ê· ê°€", "min_price": "ìµœì €ê°€", "max_price": "ìµœê³ ê°€",
            "price_range": "ê°€ê²©í­", "avg_reviews": "í‰ê· ë¦¬ë·°", "opportunity_score": "ì§„ì…ì ìˆ˜",
            "total_products": "ìƒ˜í”Œìˆ˜", "accuracy_rating": "ì‹ ë¢°ë„",
        }
        df_renamed = df_filtered.rename(columns=col_map)
        styled = _style_rocket_zero(df_renamed, "ë¡œì¼“ìˆ˜") if "rocket_count" in df_filtered.columns else df_renamed.style
        price_cols = [c for c in ["avg_price", "min_price", "max_price", "price_range"] if c in df_filtered.columns]
        if price_cols:
            fmt_map = {col_map[c]: "{:,.0f}" for c in price_cols if col_map[c] in df_renamed.columns}
            if fmt_map:
                styled = styled.format(fmt_map)
        st.dataframe(styled, use_container_width=True, hide_index=True)
    else:
        st.warning("niche_score_report.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒë‹¨ 'ğŸ“ˆ ì¿ íŒ¡ ì‹œì¥ì„± ë¶„ì„' ë²„íŠ¼ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

# === íƒ­3: ë‹ˆì¹˜ ë¶„ì„ (niche_analysis ê²°ê³¼) ===
with tab3:
    if NICHE_ANALYSIS.exists():
        df = pd.read_csv(NICHE_ANALYSIS, encoding="utf-8-sig")
        st.subheader("ì¿ íŒ¡ ë‹ˆì¹˜ ë¶„ì„ (ë¡œì¼“/ê°€ê²©/ë¦¬ë·°)")
        st.write(f"ì´ **{len(df)}**ê°œ í‚¤ì›Œë“œ")
        grade_filter = st.multiselect("ë“±ê¸‰ í•„í„°", ["S", "A", "B"], default=["S", "A"])
        df_filtered = df[df["grade"].isin(grade_filter)]
        col_map = {
            "category": "ì¹´í…Œê³ ë¦¬", "rank": "ìˆœìœ„", "keyword": "í‚¤ì›Œë“œ", "change_trend": "ë³€í™”ì¶”ì´",
            "rocket_count": "ë¡œì¼“ìˆ˜", "total_products": "ìƒí’ˆìˆ˜", "avg_price": "í‰ê· ê°€",
            "max_reviews": "ìµœëŒ€ë¦¬ë·°", "grade": "ë“±ê¸‰",
        }
        df_renamed = df_filtered.rename(columns=col_map)
        styled = _style_rocket_zero(df_renamed, "ë¡œì¼“ìˆ˜") if "rocket_count" in df_filtered.columns else df_renamed.style
        if "avg_price" in df_filtered.columns:
            styled = styled.format({"í‰ê· ê°€": "{:,.0f}"})
        st.dataframe(styled, use_container_width=True, hide_index=True)
    else:
        st.warning("niche_analysis.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒë‹¨ 'ğŸ” ì¿ íŒ¡ ë‹ˆì¹˜ ë¶„ì„' ë²„íŠ¼ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

# === íƒ­4: ë‹ˆì¹˜ í…ŒìŠ¤íŠ¸ (ìƒìœ„ 20ê°œ) ===
with tab4:
    if NICHE_TEST.exists():
        df = pd.read_csv(NICHE_TEST, encoding="utf-8-sig")
        st.subheader("ì¿ íŒ¡ ë‹ˆì¹˜ í…ŒìŠ¤íŠ¸ (ìƒìœ„ 20ê°œ)")
        st.write(f"ì´ **{len(df)}**ê°œ í‚¤ì›Œë“œ | ì£¼í™©ìƒ‰ í–‰ = ë¡œì¼“ 0 â†’ ìˆ˜ë™ ê²€ì¦ í•„ìš”")
        grade_filter = st.multiselect("ë“±ê¸‰ í•„í„° ", ["S", "A", "B"], default=["S", "A"], key="grade_filter_test")
        df_filtered = df[df["grade"].isin(grade_filter)]
        col_map = {
            "category": "ì¹´í…Œê³ ë¦¬", "rank": "ìˆœìœ„", "keyword": "í‚¤ì›Œë“œ", "change_trend": "ë³€í™”ì¶”ì´",
            "rocket_count": "ë¡œì¼“ìˆ˜", "total_products": "ìƒí’ˆìˆ˜", "avg_price": "í‰ê· ê°€",
            "max_reviews": "ìµœëŒ€ë¦¬ë·°", "grade": "ë“±ê¸‰",
        }
        df_valid = _add_validation_icon(df_filtered, "rocket_count")
        col_map["_validation"] = "âš ï¸ê²€ì¦"

        col_tbl, col_val = st.columns([3, 1])
        with col_tbl:
            df_renamed = df_valid.rename(columns=col_map)
            styled = _style_rocket_zero(df_renamed, "ë¡œì¼“ìˆ˜") if "rocket_count" in df_valid.columns else df_renamed.style
            if "í‰ê· ê°€" in df_renamed.columns:
                styled = styled.format({"í‰ê· ê°€": "{:,.0f}"})
            st.dataframe(styled, use_container_width=True, hide_index=True)

        with col_val:
            keywords_list = df_filtered["keyword"].dropna().astype(str).tolist()
            selected_kw = st.selectbox("í‚¤ì›Œë“œ ì„ íƒ (ê²€ì¦ ì´ë¯¸ì§€)", [""] + keywords_list, key="kw_select_niche")
            if selected_kw:
                safe_name = "".join(c if c.isalnum() or c in "._-" else "_" for c in selected_kw)
                for p in [DEBUG_SCREENSHOTS / f"{safe_name}.png", DEBUG_SCREENSHOTS / f"{selected_kw}.png", BASE / "debug_screenshot.png"]:
                    if p.exists():
                        st.image(str(p), caption=f"ê²€ì¦: {selected_kw}", use_container_width=True)
                        break
                else:
                    st.caption("ê²€ì¦ ìŠ¤í¬ë¦°ìƒ· ì—†ìŒ (debug_screenshots/ í´ë”)")

                # ìˆ˜ë™ ê²€ì¦ ì¬ì¡°ì‚¬: ì‹œê° ìŠ¤í¬ë˜í¼ë¡œ í•´ë‹¹ í‚¤ì›Œë“œë§Œ ì¬ë¶„ì„ â†’ niche_test.csv, DB ë°˜ì˜
                if st.button("ğŸ” ìˆ˜ë™ ê²€ì¦ ì¬ì¡°ì‚¬", key="btn_verify_rescan"):
                    sys.path.insert(0, str(BASE))
                    try:
                        from coupang_visual_fallback import scrape_and_save
                        from core.database import update_product_rocket_count
                        fallback = scrape_and_save(selected_kw)
                        if fallback.get("error"):
                            st.error(f"ì‹œê° ê²€ì¦ ì‹¤íŒ¨: {fallback['error']} (ì¿ íŒ¡ ì°¨ë‹¨ ì‹œ ë°œìƒ)")
                        else:
                            new_rocket = fallback.get("rocket_count", 0)
                            # niche_test.csv í•´ë‹¹ í–‰ ì—…ë°ì´íŠ¸
                            ntf = pd.read_csv(NICHE_TEST, encoding="utf-8-sig")
                            mask = ntf["keyword"] == selected_kw
                            if mask.any():
                                ntf.loc[mask, "rocket_count"] = new_rocket
                                ntf.loc[mask, "verification_needed"] = ""
                                grade = "S" if new_rocket < 5 else ("A" if new_rocket <= 10 else "B")
                                ntf.loc[mask, "grade"] = grade
                                ntf.to_csv(NICHE_TEST, index=False, encoding="utf-8-sig")
                            # DB ë°˜ì˜
                            opp = 80 - new_rocket * 5 if new_rocket < 15 else 10
                            updated = update_product_rocket_count(selected_kw, new_rocket, opp)
                            st.success(f"ì¬ì¡°ì‚¬ ì™„ë£Œ: ë¡œì¼“ {new_rocket}ê°œ | DB ë°˜ì˜: {'ë¨' if updated else 'í•´ë‹¹ ì—†ìŒ'}")
                            st.rerun()
                    except Exception as e:
                        st.error(f"ì¬ì¡°ì‚¬ ì˜¤ë¥˜: {e}")

                with st.expander(f"ğŸ“Š {selected_kw} ìƒì„¸ ë¶„ì„"):
                    if st.button("3ë…„ íŠ¸ë Œë“œ + ê²€ìƒ‰ëŸ‰ ì¡°íšŒ", key=f"fetch_{selected_kw}"):
                        sys.path.insert(0, str(BASE))
                        from dashboard_helpers import fetch_trend_3year, fetch_search_volume
                        periods, ratios = fetch_trend_3year(selected_kw)
                        vol = fetch_search_volume(selected_kw)
                        st.session_state["keyword_detail"] = {"kw": selected_kw, "periods": periods, "ratios": ratios, "vol": vol}
                    detail = st.session_state.get("keyword_detail", {})
                    if detail.get("kw") == selected_kw and (detail.get("periods") or detail.get("vol")):
                        if detail.get("periods") and detail.get("ratios") and HAS_PLOTLY:
                            fig = go.Figure()
                            fig.add_trace(go.Scatter(x=detail["periods"], y=detail["ratios"], mode="lines+markers", name="ê²€ìƒ‰ëŸ‰(ìƒëŒ€)"))
                            fig.update_layout(title=f"'{selected_kw}' 3ë…„ íŠ¸ë Œë“œ", xaxis_title="ì›”", height=250)
                            st.plotly_chart(fig, use_container_width=True)
                        if detail.get("vol") is not None:
                            st.metric("ì‹¤ì‹œê°„ ê²€ìƒ‰ëŸ‰ (ì›”)", f"{int(detail['vol']):,}")
                    elif st.session_state.get("keyword_detail", {}).get("kw") == selected_kw and not detail.get("periods") and detail.get("vol") is None:
                        st.info("API í‚¤ í™•ì¸ í•„ìš” (config.py)")
                    if not HAS_PLOTLY:
                        st.caption("pip install plotly")
    else:
        st.warning("niche_test.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒë‹¨ 'ğŸ§ª ë‹ˆì¹˜ í…ŒìŠ¤íŠ¸ (ìƒìœ„ 20ê°œ)' ë²„íŠ¼ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

# === íƒ­5: ê²€ìƒ‰ëŸ‰ (niche_with_volume / trending_with_volume) ===
with tab5:
    vol_df = None
    vol_title = ""
    if NICHE_WITH_VOLUME.exists():
        vol_df = pd.read_csv(NICHE_WITH_VOLUME, encoding="utf-8-sig")
        vol_title = "ê²€ìƒ‰ëŸ‰ í¬í•¨ ë‹ˆì¹˜ ê²°ê³¼ (niche_with_volume.csv)"
    elif TRENDING_WITH_VOLUME.exists():
        vol_df = pd.read_csv(TRENDING_WITH_VOLUME, encoding="utf-8-sig")
        vol_title = "ê²€ìƒ‰ëŸ‰ í¬í•¨ íŠ¸ë Œë“œ (trending_with_volume.csv)"
    if vol_df is not None and not vol_df.empty:
        st.subheader(vol_title)
        st.write(f"ì´ **{len(vol_df)}**ê°œ í‚¤ì›Œë“œ (ê²€ìƒ‰ëŸ‰â†‘ ë¡œì¼“â†“ ìˆœ ì •ë ¬)")
        st.caption("niche_test.csvì— ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  APIë¡œ ê²€ìƒ‰ëŸ‰ ì¶”ê°€. ìƒë‹¨ 'ğŸ“Š ê²€ìƒ‰ëŸ‰ ìˆ˜ì§‘' ë²„íŠ¼ìœ¼ë¡œ ìƒì„±.")
        col_map_vol = {c: c for c in vol_df.columns}
        if "keyword" in vol_df.columns:
            col_map_vol["keyword"] = "í‚¤ì›Œë“œ"
        if "rocket_count" in vol_df.columns:
            col_map_vol["rocket_count"] = "ë¡œì¼“ìˆ˜"
        vol_display = vol_df.rename(columns=col_map_vol)
        st.dataframe(vol_display, use_container_width=True, hide_index=True)
    else:
        st.warning("niche_with_volume.csvê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ğŸ§ª ë‹ˆì¹˜ í…ŒìŠ¤íŠ¸'ë¥¼ ì‹¤í–‰í•œ ë’¤ 'ğŸ“Š ê²€ìƒ‰ëŸ‰ ìˆ˜ì§‘' ë²„íŠ¼ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

# === íƒ­6: ì†Œì‹± ë¦¬ìŠ¤íŠ¸ (final_sourcing_list) ===
with tab6:
    if FINAL_SOURCING.exists():
        df = pd.read_csv(FINAL_SOURCING, encoding="utf-8-sig")
        st.subheader("ìµœì¢… ì†Œì‹± ë¦¬ìŠ¤íŠ¸ (ìµœì¢… ìˆœë§ˆì§„ 15% ì´ìƒ)")
        st.caption("ê´‘ê³ ë¹„(15%)Â·ìˆ˜ìˆ˜ë£ŒÂ·ë°°ì†¡ë¹„Â·ë¶€ê°€ì„¸ ë°˜ì˜ í›„ ìˆœì´ìµ ê¸°ì¤€ (ê´‘ê³ ë¹„ ì œì™¸ í›„ ìˆœì´ìµ)")
        st.write(f"ì´ **{len(df)}**ê±´")
        col_config = {}
        if "ë„ë§¤ì²˜ë§í¬" in df.columns:
            col_config["ë„ë§¤ì²˜ë§í¬"] = st.column_config.LinkColumn("ë„ë§¤ì²˜ë§í¬", display_text="ì—´ê¸°")
        if "ì¿ íŒ¡ê°€" in df.columns:
            col_config["ì¿ íŒ¡ê°€"] = st.column_config.NumberColumn("ì¿ íŒ¡ê°€", format="%dì›")
        if "ë„ë§¤ê°€(ìµœì €)" in df.columns:
            col_config["ë„ë§¤ê°€(ìµœì €)"] = st.column_config.NumberColumn("ë„ë§¤ê°€(ìµœì €)", format="%dì›")
        if "ì˜ˆìƒ ìˆœì´ìµ" in df.columns:
            col_config["ì˜ˆìƒ ìˆœì´ìµ"] = st.column_config.NumberColumn("ì˜ˆìƒ ìˆœì´ìµ", format="%dì›")
        if "ìµœì¢… ìˆœë§ˆì§„ì•¡" in df.columns:
            col_config["ìµœì¢… ìˆœë§ˆì§„ì•¡"] = st.column_config.NumberColumn(
                "ìµœì¢… ìˆœë§ˆì§„ì•¡ (ê´‘ê³ ë¹„ ì œì™¸ ìˆœì´ìµ)", format="%dì›",
                help="ê´‘ê³ ë¹„Â·ìˆ˜ìˆ˜ë£ŒÂ·ë°°ì†¡ë¹„Â·ë¶€ê°€ì„¸ ì°¨ê° í›„ ìˆœì´ìµ"
            )
        if "ìµœì¢… ìˆœë§ˆì§„ìœ¨" in df.columns:
            col_config["ìµœì¢… ìˆœë§ˆì§„ìœ¨"] = st.column_config.TextColumn("ìµœì¢… ìˆœë§ˆì§„ìœ¨")
        if "ìˆœë§ˆì§„ìœ¨" in df.columns:
            col_config["ìˆœë§ˆì§„ìœ¨"] = st.column_config.TextColumn("ìˆœë§ˆì§„ìœ¨")
        if "ìµœì¢… ì†Œì‹±ì²˜" in df.columns:
            col_config["ìµœì¢… ì†Œì‹±ì²˜"] = st.column_config.TextColumn("ìµœì¢… ì†Œì‹±ì²˜", help="ë„ë§¤ê¾¹/ì˜¤ë„ˆí´ëœ ì¤‘ ë” ì €ë ´í•œ ê³³")
        st.dataframe(df, use_container_width=True, hide_index=True, column_config=col_config or None)
    else:
        st.warning("final_sourcing_list.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒë‹¨ 'ğŸª ë„ë§¤ ê²€ìƒ‰ (ì†Œì‹± ë¦¬ìŠ¤íŠ¸)' ë²„íŠ¼ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

# === íƒ­7: ì‹ ë¢°ë„ ë¦¬í¬íŠ¸ ===
with tab7:
    if MARKET_CREDIBILITY.exists():
        df = pd.read_csv(MARKET_CREDIBILITY, encoding="utf-8-sig")
        st.subheader("ë°ì´í„° ê¸°ë°˜ ì§„ì… ì‹ ë¢°ë„ ë¦¬í¬íŠ¸")
        st.write(f"ì´ **{len(df)}**ê±´")
        st.caption("ì´ê±´ ì§€ê¸ˆ ì‚¬ì•¼ í•´(ì‹œì¦Œ) | ì´ê±´ 1ë…„ ë‚´ë‚´ íŒ”ë ¤(ìŠ¤í…Œë””) | ì´ê±´ í•¨ì •(í•˜ë½ì„¸)")
        rec_filter = st.multiselect("ì§„ì…ê¶Œì¥ í•„í„°", df["ì§„ì…ê¶Œì¥ì—¬ë¶€"].unique().tolist(), default=df["ì§„ì…ê¶Œì¥ì—¬ë¶€"].unique().tolist(), key="rec_filter")
        df_filtered = df[df["ì§„ì…ê¶Œì¥ì—¬ë¶€"].isin(rec_filter)]
        st.dataframe(df_filtered, use_container_width=True, hide_index=True)
        charts_dir = BASE / "credibility_charts"
        if charts_dir.exists():
            imgs = list(charts_dir.glob("*.png"))
            if imgs:
                st.subheader("ìƒìœ„ 5ê°œ ê²€ìƒ‰ëŸ‰ ì¶”ì´")
                for p in sorted(imgs)[:5]:
                    st.image(str(p), caption=p.stem, use_container_width=True)
    else:
        st.warning("market_credibility_report.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒë‹¨ 'ğŸ“‹ ì‹ ë¢°ë„ ë¦¬í¬íŠ¸' ë²„íŠ¼ì„ ì‹¤í–‰í•˜ì„¸ìš”. (config.pyì— ë„¤ì´ë²„ ë°ì´í„°ë© API í‚¤ í•„ìš”)")

# === íƒ­8: ì‚¬ì… ì í•© ===
with tab8:
    if LIGHT_WEIGHT.exists():
        df = pd.read_excel(LIGHT_WEIGHT, engine="openpyxl")
        st.subheader("ì‚¬ì… ì í•©ì„± í•„í„° (light_weight_niche.xlsx)")
        st.write(f"ì´ **{len(df)}**ê±´ (ê°€ê²© 1.5~6ë§Œì›, ë¶€í”¼ í° í’ˆëª© ì œì™¸, ë¬¶ìŒ ê°€ì‚°)")
        price_cols = [c for c in ["í‰ê· ê°€", "avg_price"] if c in df.columns]
        if price_cols:
            df_display = df.copy()
            try:
                df_display = df_display.style.format({price_cols[0]: "{:,.0f}"})
            except Exception:
                pass
            st.dataframe(df_display, use_container_width=True, hide_index=True)
        else:
            st.dataframe(df, use_container_width=True, hide_index=True)
    else:
        st.warning("light_weight_niche.xlsx íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒë‹¨ 'ğŸ“¦ ì‚¬ì… ì í•©ì„± í•„í„°' ë²„íŠ¼ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

# === íƒ­9: DB (SQLite) ===
with tab9:
    if DB_PATH.exists():
        try:
            import sqlite3
            conn = sqlite3.connect(str(DB_PATH))
            # Products í…Œì´ë¸” ìš°ì„  (ë§ˆìŠ¤í„° ì‹œìŠ¤í…œ)
            try:
                df = pd.read_sql_query("SELECT keyword, category, naver_rank, naver_search_vol, coupang_avg_price, rocket_count, opportunity_score, updated_at FROM Products ORDER BY updated_at DESC LIMIT 200", conn)
                col_map = {"keyword": "í‚¤ì›Œë“œ", "category": "ì¹´í…Œê³ ë¦¬", "naver_rank": "ë„¤ì´ë²„ìˆœìœ„", "naver_search_vol": "ë„¤ì´ë²„ê²€ìƒ‰ëŸ‰", "coupang_avg_price": "í‰ê· ê°€", "rocket_count": "ë¡œì¼“ìˆ˜", "opportunity_score": "ì§„ì…ì ìˆ˜", "updated_at": "ìˆ˜ì •ì¼ì‹œ"}
            except Exception:
                df = pd.read_sql_query("SELECT keyword, category, collected_at, naver_rank, coupang_rocket_count, coupang_avg_price, consistency_score, validation_status FROM keyword_data ORDER BY collected_at DESC LIMIT 200", conn)
                col_map = {"keyword": "í‚¤ì›Œë“œ", "category": "ì¹´í…Œê³ ë¦¬", "collected_at": "ìˆ˜ì§‘ì¼ì‹œ", "naver_rank": "ë„¤ì´ë²„ìˆœìœ„", "coupang_rocket_count": "ë¡œì¼“ìˆ˜", "coupang_avg_price": "í‰ê· ê°€", "consistency_score": "ì¼ê´€ì„±ì ìˆ˜", "validation_status": "ê²€ì¦ìƒíƒœ"}
            conn.close()
            st.subheader("SQLite DB (Products)")
            st.write(f"ìµœê·¼ **{len(df)}**ê±´")
            df_display = df.rename(columns=col_map)
            fmt_cols = {c: "{:,.0f}" for c in ["í‰ê· ê°€"] if c in df_display.columns}
            fmt_cols.update({c: "{:.1f}" for c in ["ì¼ê´€ì„±ì ìˆ˜", "ì§„ì…ì ìˆ˜", "ë„¤ì´ë²„ê²€ìƒ‰ëŸ‰"] if c in df_display.columns})
            if fmt_cols:
                df_display = df_display.style.format(fmt_cols)
            st.dataframe(df_display, use_container_width=True, hide_index=True)
        except Exception as e:
            st.error(f"DB ì¡°íšŒ ì˜¤ë¥˜: {e}")
    else:
        st.warning("coupang_gross.db ì—†ìŒ. ìƒë‹¨ 'ğŸ”„ ë§ˆìŠ¤í„° íŒŒì´í”„ë¼ì¸' ì‹¤í–‰ í›„ ìƒì„±ë©ë‹ˆë‹¤.")

# === íƒ­10: ì‹œì¦Œ í—Œí„° ===
with tab10:
    if SEASONAL_HUNTER.exists():
        df = pd.read_csv(SEASONAL_HUNTER, encoding="utf-8-sig")
        st.subheader("ì‹œì¦Œ í—Œí„° - ë°˜ë³µ ì‹œì¦Œ í‚¤ì›Œë“œ")
        st.write(f"ì´ **{len(df)}**ê°œ í‚¤ì›Œë“œ ë¶„ì„")
        st.caption("ë§¤ë…„ íŠ¹ì • ì›”ì—ë§Œ ê²€ìƒ‰ëŸ‰ì´ í­ë“±í•˜ëŠ” í‚¤ì›Œë“œ. ì•ìœ¼ë¡œ 2ê°œì›” ë‚´ í­ë“± ì˜ˆì •ì„ ì„ ì œì ìœ¼ë¡œ í™•ì¸í•˜ì„¸ìš”.")
        upcoming_filter = st.radio("2ê°œì›” ë‚´ í­ë“± ì˜ˆì •ë§Œ", ["ì „ì²´", "ì˜ˆì •ë§Œ"], horizontal=True, key="seasonal_filter")
        if upcoming_filter == "ì˜ˆì •ë§Œ":
            df_filtered = df[df["2ê°œì›” ë‚´ í­ë“± ì˜ˆì •"] == "ì˜ˆ"]
        else:
            df_filtered = df
        st.dataframe(df_filtered, use_container_width=True, hide_index=True)
        if SEASONAL_CHARTS.exists():
            imgs = list(SEASONAL_CHARTS.glob("*.png"))
            if imgs:
                st.subheader("3ë…„ì¹˜ ê²€ìƒ‰ëŸ‰ ì¶”ì´ ì°¨íŠ¸")
                for p in sorted(imgs)[:5]:
                    st.image(str(p), caption=p.stem.replace("_3year", ""), use_container_width=True)
    else:
        st.warning("seasonal_hunter_report.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒë‹¨ 'ğŸ“… ì‹œì¦Œ í—Œí„°' ë²„íŠ¼ì„ ì‹¤í–‰í•˜ì„¸ìš”. (config.pyì— ë„¤ì´ë²„ ë°ì´í„°ë© API í‚¤ í•„ìš”)")

# === íƒ­11: ìš”ì•½ ===
with tab11:
    st.subheader("ğŸ“‹ ì‹¤í–‰ ê°€ì´ë“œ")
    st.markdown("""
    | ìˆœì„œ | ìƒë‹¨ ë²„íŠ¼ | ê²°ê³¼ |
    |------|-----------|------|
    | 1 | ğŸ“¥ ë„¤ì´ë²„ íŠ¸ë Œë“œ ìŠ¤í¬ë˜í•‘ | trending_keywords.csv |
    | 2 | ğŸ“ˆ ì¿ íŒ¡ ì‹œì¥ì„± ë¶„ì„ | niche_score_report.csv |
    | 3 | ğŸ” ì¿ íŒ¡ ë‹ˆì¹˜ ë¶„ì„ | niche_analysis.csv |
    | 4 | ğŸ§ª ë‹ˆì¹˜ í…ŒìŠ¤íŠ¸ (ìƒìœ„ 20ê°œ) | niche_test.csv |
    | 5 | ğŸ“Š ê²€ìƒ‰ëŸ‰ ìˆ˜ì§‘ | niche_with_volume.csv |
    | 6 | ğŸª ë„ë§¤ ê²€ìƒ‰ (ì†Œì‹± ë¦¬ìŠ¤íŠ¸) | final_sourcing_list.csv |
    | 7 | ğŸ“‹ ì‹ ë¢°ë„ ë¦¬í¬íŠ¸ | market_credibility_report.csv |
    | 8 | ğŸ“¦ ì‚¬ì… ì í•©ì„± í•„í„° | light_weight_niche.xlsx |
    | 9 | ğŸ“… ì‹œì¦Œ í—Œí„° | seasonal_hunter_report.csv |
    | 10 | ğŸ”„ ë§ˆìŠ¤í„° íŒŒì´í”„ë¼ì¸ | coupang_gross.db (Products) |
    """)
    st.info("ëª¨ë“  ì‘ì—…ì€ ìƒë‹¨ ë²„íŠ¼ì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨(F5)í•˜ë©´ ìµœì‹  CSV ë°ì´í„°ê°€ ë°˜ì˜ë©ë‹ˆë‹¤.")
    st.caption("ğŸ’¡ Cursor í„°ë¯¸ë„ì—ì„œ í•œê¸€ ê²½ë¡œ ë•Œë¬¸ì— ì˜¤ë¥˜ê°€ ë‚˜ë©´: ëŒ€ì‹œë³´ë“œ ë²„íŠ¼ìœ¼ë¡œ ì‹¤í–‰í•˜ê±°ë‚˜, í´ë”ì—ì„œ run_web.bat / run_niche_test.bat ë“±ì„ ë”ë¸”í´ë¦­í•´ì„œ ì‹¤í–‰í•˜ì„¸ìš”.")

# === ì‹¤í–‰ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë° (í•˜ë‹¨) ===
st.divider()
with st.expander("ğŸ“œ ì‹¤í–‰ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë°", expanded=False):
    if "last_output" in st.session_state:
        st.caption("ë§ˆì§€ë§‰ ì‹¤í–‰ ê²°ê³¼")
        st.text_area("stdout", st.session_state["last_output"], height=200, disabled=True, key="log_area")
    log_path = BASE / "logs" / "dashboard_run.log"
    if log_path.exists():
        try:
            with open(log_path, "r", encoding="utf-8", errors="replace") as f:
                lines = f.readlines()
            tail = "".join(lines[-100:]) if len(lines) > 100 else "".join(lines)
            st.caption("ë¡œê·¸ íŒŒì¼ (logs/dashboard_run.log ìµœê·¼ 100ì¤„)")
            st.text_area("dashboard_run.log", tail, height=150, disabled=True, key="log_file_area")
        except Exception as e:
            st.caption(f"ë¡œê·¸ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
