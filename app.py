"""
ì¿ íŒ¡ê·¸ë¡œìŠ¤ ëŒ€ì‹œë³´ë“œ - ì›¹ì—ì„œ ë°ì´í„° í™•ì¸ ë° ì‘ì—… ì‹¤í–‰
ë°ì´í„° ê²€ì¦(Validation) ì‹œê°í™” í¬í•¨
"""

import os
import subprocess
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Any

import pandas as pd
import streamlit as st

try:
    import plotly.graph_objects as go
    HAS_PLOTLY = True
except ImportError:
    HAS_PLOTLY = False

st.set_page_config(
    page_title="ì¿ íŒ¡ê·¸ë¡œìŠ¤ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ›’",
    layout="wide",
)

# ë°ì´í„° íŒŒì¼ ê²½ë¡œ (ì ˆëŒ€ê²½ë¡œë¡œ ê³ ì •í•´ í•œê¸€ ê²½ë¡œ/í„°ë¯¸ë„ ì¸ì½”ë”© ë¬¸ì œ ì™„í™”)
BASE = Path(__file__).resolve().parent
TRENDING = BASE / "trending_keywords.csv"
NICHE_SCORE = BASE / "niche_score_report.csv"
NICHE_ANALYSIS = BASE / "niche_analysis.csv"
NICHE_TEST = BASE / "niche_test.csv"
FINAL_SOURCING = BASE / "final_sourcing_list.csv"
MARKET_CREDIBILITY = BASE / "market_credibility_report.csv"
SEASONAL_HUNTER = BASE / "seasonal_hunter_report.csv"
SEASONAL_CHARTS = BASE / "seasonal_charts"
NICHE_WITH_VOLUME = BASE / "niche_with_volume.csv"
TRENDING_WITH_VOLUME = BASE / "trending_with_volume.csv"
LIGHT_WEIGHT = BASE / "light_weight_niche.xlsx"
DB_PATH = BASE / "coupang_gross.db"
DEBUG_SCREENSHOTS = BASE / "debug_screenshots"
WHOLESALE_LOGIN_STATUS = BASE / "wholesale_login_status.json"


def _read_wholesale_login_status():
    if not WHOLESALE_LOGIN_STATUS.exists():
        return None
    try:
        import json
        with open(WHOLESALE_LOGIN_STATUS, "r", encoding="utf-8") as f:
            return json.load(f)
    except Exception:
        return None


def run_script(script_name: str, desc: str) -> tuple[str, int]:
    """Python ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰, (ì¶œë ¥í…ìŠ¤íŠ¸, ë¦¬í„´ì½”ë“œ) ë°˜í™˜. ë¡œê·¸ íŒŒì¼ì—ë„ ê¸°ë¡."""
    script_path = (BASE / script_name).resolve()
    if not script_path.exists():
        return f"ì˜¤ë¥˜: {script_name} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", 1
    env = {**os.environ, "PYTHONIOENCODING": "utf-8"}
    try:
        result = subprocess.run(
            [sys.executable, "-u", str(script_path)],
            cwd=str(BASE),
            capture_output=True,
            text=True,
            encoding="utf-8",
            errors="replace",
            timeout=3600,
            env=env,
        )
        out = (result.stdout or "") + (result.stderr or "")
        out_stripped = out.strip() or f"{desc} ì™„ë£Œ (ì¶œë ¥ ì—†ìŒ)"
        log_dir = BASE / "logs"
        log_dir.mkdir(parents=True, exist_ok=True)
        try:
            from datetime import datetime
            with open(log_dir / "dashboard_run.log", "a", encoding="utf-8") as f:
                f.write(f"\n=== {datetime.now().isoformat()} | {script_name} ===\n{out_stripped}\n")
        except Exception:
            pass
        return out_stripped, result.returncode
    except subprocess.TimeoutExpired:
        return "ì˜¤ë¥˜: ì‹¤í–‰ ì‹œê°„ ì´ˆê³¼ (1ì‹œê°„)", 1
    except Exception as e:
        return f"ì˜¤ë¥˜: {e}", 1


# ìƒë‹¨: ì œëª©(ì¢Œ) + ë„ë§¤ ë¡œê·¸ì¸ ì‹ í˜¸ë“±(ìš°)
_header_left, _header_right = st.columns([3, 1])
with _header_left:
    st.title("ğŸ›’ ì¿ íŒ¡ê·¸ë¡œìŠ¤ ëŒ€ì‹œë³´ë“œ")
    st.caption("ë„¤ì´ë²„ íŠ¸ë Œë“œ í‚¤ì›Œë“œ & ì¿ íŒ¡ ì‹œì¥ì„± ë¶„ì„ ê²°ê³¼")
with _header_right:
    _ls = _read_wholesale_login_status()
    _dg = _ls.get("domeggook") if _ls else None
    _oc = _ls.get("ownerclan") if _ls else None
    st.markdown("**ë„ë§¤ ë¡œê·¸ì¸**")
    if _dg is True:
        st.markdown("ğŸŸ¢ ë„ë§¤ê¾¹")
    elif _dg is False:
        st.markdown("ğŸ”´ ë„ë§¤ê¾¹")
    else:
        st.markdown("âšª ë„ë§¤ê¾¹")
    if _oc is True:
        st.markdown("ğŸŸ¢ ì˜¤ë„ˆí´ëœ")
    elif _oc is False:
        st.markdown("ğŸ”´ ì˜¤ë„ˆí´ëœ")
    else:
        st.markdown("âšª ì˜¤ë„ˆí´ëœ")
    if st.button("ìƒíƒœ í™•ì¸", key="btn_wholesale_check", help="ë¡œê·¸ì¸ ì‹œë„ í›„ ì‹ í˜¸ë“± ê°±ì‹ . ë¸Œë¼ìš°ì € ì°½ì´ ì ì‹œ ì—´ë¦½ë‹ˆë‹¤."):
        with st.spinner("í™•ì¸ ì¤‘..."):
            run_script("check_wholesale_login.py", "ë¡œê·¸ì¸ ìƒíƒœ í™•ì¸")
        st.rerun()


def _style_rocket_zero(df: pd.DataFrame, rocket_col: str = "rocket_count") -> Any:
    """ë¡œì¼“ìˆ˜ 0ì¸ í–‰ ì£¼í™©ìƒ‰ ê°•ì¡°"""
    if rocket_col not in df.columns:
        return df.style
    def _row_style(row):
        try:
            rc = row.get(rocket_col)
            if rc is not None and (rc == 0 or rc == "0"):
                return ["background-color: #ffcc80"] * len(row)
        except Exception:
            pass
        return [""] * len(row)
    return df.style.apply(_row_style, axis=1)


def _add_validation_icon(df: pd.DataFrame, rocket_col: str = "rocket_count", vcol: str = "verification_needed") -> pd.DataFrame:
    """ë¡œì¼“ìˆ˜ 0 ë˜ëŠ” verification_needed=Yì¸ í–‰ì— ìˆ˜ë™ ê²€ì¦ í•„ìš” ì•„ì´ì½˜ ì¶”ê°€"""
    df = df.copy()
    if "_validation" not in df.columns:
        df["_validation"] = ""
    def _need(r):
        if str(r.get(vcol, "")).upper() == "Y":
            return "âš ï¸ ìˆ˜ë™ ê²€ì¦ í•„ìš”"
        if rocket_col in df.columns and r.get(rocket_col) is not None and r.get(rocket_col) == 0:
            return "âš ï¸ ìˆ˜ë™ ê²€ì¦ í•„ìš”"
        return ""
    df["_validation"] = df.apply(_need, axis=1)
    return df


# === ì‘ì—… ì‹¤í–‰ íŒ¨ë„ (ìƒë‹¨, 2ì¤„ë¡œ ì •ë¦¬) ===
st.subheader("ğŸš€ ì‘ì—… ì‹¤í–‰")
st.caption("ë²„íŠ¼ í´ë¦­ í›„ í•´ë‹¹ íƒ­ì—ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.")

r1_1, r1_2, r1_3, r1_4, r1_5 = st.columns(5)
with r1_1:
    if st.button("ğŸ“¥ íŠ¸ë Œë“œ", key="btn_scraper", help="5ê°œ ì¹´í…Œê³ ë¦¬ ìˆ˜ì§‘ â†’ ê²€ìƒ‰ëŸ‰ ìˆœ ì „ì²´ ì¸ê¸°ìˆœ ì •ë ¬ â†’ trending_keywords.csv", use_container_width=True):
        with st.spinner("ìˆ˜ì§‘Â·ê²€ìƒ‰ëŸ‰ ì¡°íšŒÂ·ì •ë ¬ ì¤‘... (ìˆ˜ ë¶„ ì†Œìš”)"):
            out, code = run_script("naver_shopping_insight_scraper.py", "ë„¤ì´ë²„ íŠ¸ë Œë“œ ìŠ¤í¬ë˜í•‘")
        st.session_state["last_output"] = out
        st.session_state["last_code"] = code
with r1_2:
    if st.button("ğŸ“ˆ ì‹œì¥ì„±", key="btn_analyzer", help="ì¿ íŒ¡ ì‹œì¥ì„± ë¶„ì„ â†’ niche_score_report.csv", use_container_width=True):
        with st.spinner("ë¶„ì„ ì¤‘..."):
            out, code = run_script("coupang_analyzer.py", "ì¿ íŒ¡ ì‹œì¥ì„± ë¶„ì„")
        st.session_state["last_output"] = out
        st.session_state["last_code"] = code
with r1_3:
    if st.button("ğŸ” ë‹ˆì¹˜ë¶„ì„", key="btn_niche", help="ì¿ íŒ¡ ë‹ˆì¹˜ ë¶„ì„ â†’ niche_analysis.csv", use_container_width=True):
        with st.spinner("ë‹ˆì¹˜ ë¶„ì„ ì¤‘..."):
            out, code = run_script("niche_analysis.py", "ì¿ íŒ¡ ë‹ˆì¹˜ ë¶„ì„")
        st.session_state["last_output"] = out
        st.session_state["last_code"] = code
with r1_4:
    if st.button("ğŸ§ª ë‹ˆì¹˜í…ŒìŠ¤íŠ¸", key="btn_niche_test", help="ìƒìœ„ í‚¤ì›Œë“œ ì¿ íŒ¡ ë¶„ì„ â†’ niche_test.csv", use_container_width=True):
        with st.spinner("ë‹ˆì¹˜ í…ŒìŠ¤íŠ¸ ì¤‘..."):
            out, code = run_script("niche_test.py", "ë‹ˆì¹˜ í…ŒìŠ¤íŠ¸")
        st.session_state["last_output"] = out
        st.session_state["last_code"] = code
with r1_5:
    if st.button("ğŸª ë„ë§¤ê²€ìƒ‰", key="btn_wholesale", help="ë„ë§¤ê¾¹Â·ì˜¤ë„ˆí´ëœ ê²€ìƒ‰ â†’ final_sourcing_list.csv", use_container_width=True):
        with st.spinner("ë„ë§¤ ê²€ìƒ‰ ì¤‘..."):
            out, code = run_script("wholesale_searcher.py", "ë„ë§¤ ê²€ìƒ‰")
        st.session_state["last_output"] = out
        st.session_state["last_code"] = code
        if code == 0:
            st.rerun()

r2_1, r2_2, r2_3, r2_4, r2_5 = st.columns(5)
with r2_1:
    if st.button("ğŸ“‹ ì‹ ë¢°ë„", key="btn_credibility", help="ê²€ìƒ‰ íŠ¸ë Œë“œÂ·ì‹ ë¢°ë„ â†’ market_credibility_report.csv", use_container_width=True):
        with st.spinner("ì‹ ë¢°ë„ ìƒì„± ì¤‘..."):
            out, code = run_script("market_credibility_report.py", "ì‹ ë¢°ë„ ë¦¬í¬íŠ¸")
        st.session_state["last_output"] = out
        st.session_state["last_code"] = code
with r2_2:
    if st.button("ğŸ“¦ ì‚¬ì…ì í•©", key="btn_light", help="ê²½ëŸ‰Â·ê³ ë§ˆì§„ í•„í„° â†’ light_weight_niche.xlsx", use_container_width=True):
        with st.spinner("ì‚¬ì… ì í•©ì„± í•„í„° ì¤‘..."):
            out, code = run_script("light_weight_filter.py", "ì‚¬ì… ì í•©ì„± í•„í„°")
        st.session_state["last_output"] = out
        st.session_state["last_code"] = code
with r2_3:
    if st.button("ğŸ”„ ë§ˆìŠ¤í„°", key="btn_main", help="íŠ¸ë Œë“œâ†’DBâ†’ë¶„ì„ ì¼ê´„ ì‹¤í–‰", use_container_width=True):
        with st.spinner("ë§ˆìŠ¤í„° íŒŒì´í”„ë¼ì¸ ì¤‘..."):
            out, code = run_script("run_master.py", "ë§ˆìŠ¤í„° íŒŒì´í”„ë¼ì¸")
        st.session_state["last_output"] = out
        st.session_state["last_code"] = code
with r2_4:
    if st.button("ğŸ“… ì‹œì¦Œ", key="btn_seasonal", help="3ë…„ ì‹œì¦Œ íŒ¨í„´ â†’ seasonal_hunter_report.csv", use_container_width=True):
        with st.spinner("ì‹œì¦Œ í—Œí„° ì¤‘..."):
            out, code = run_script("seasonal_analyzer.py", "ì‹œì¦Œ í—Œí„°")
        st.session_state["last_output"] = out
        st.session_state["last_code"] = code
with r2_5:
    if st.button("ğŸ“Š ê²€ìƒ‰ëŸ‰", key="btn_volume", help="ë„¤ì´ë²„ ê²€ìƒ‰ëŸ‰ ì¶”ê°€ â†’ niche_with_volume.csv", use_container_width=True):
        with st.spinner("ê²€ìƒ‰ëŸ‰ ìˆ˜ì§‘ ì¤‘..."):
            out, code = run_script("naver_api_manager.py", "ê²€ìƒ‰ëŸ‰ ìˆ˜ì§‘")
        st.session_state["last_output"] = out
        st.session_state["last_code"] = code

# ì‹¤í–‰ ë¡œê·¸: ì ‘ì´ì‹ (ê¸°ë³¸ ì ‘íŒ ìƒíƒœ)
if "last_output" in st.session_state:
    code = st.session_state.get("last_code", 0)
    with st.expander("ğŸ“œ ì‹¤í–‰ ê²°ê³¼ ë¡œê·¸", expanded=False):
        if code == 0:
            st.success("ì‹¤í–‰ ì™„ë£Œ")
        else:
            st.error("ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        st.code(st.session_state["last_output"], language="text")

st.divider()

# íƒ­ êµ¬ì„±
tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8, tab9, tab10, tab11 = st.tabs(
    ["ğŸ“Š íŠ¸ë Œë“œ", "ğŸ“ˆ ì‹œì¥ì„±", "ğŸ” ë‹ˆì¹˜", "ğŸ§ª ë‹ˆì¹˜í…ŒìŠ¤íŠ¸", "ğŸ“Š ê²€ìƒ‰ëŸ‰", "ğŸª ì†Œì‹±", "ğŸ“‹ ì‹ ë¢°ë„", "ğŸ“¦ ì‚¬ì…ì í•©", "ğŸ—„ï¸ DB", "ğŸ“… ì‹œì¦Œí—Œí„°", "ğŸ“‹ ìš”ì•½"]
)

# === íƒ­1: íŠ¸ë Œë“œ í‚¤ì›Œë“œ ===
with tab1:
    if TRENDING.exists():
        df = pd.read_csv(TRENDING, encoding="utf-8-sig")
        st.subheader("ë„¤ì´ë²„ ì‡¼í•‘ ì¸ì‚¬ì´íŠ¸ ì¸ê¸° ê²€ìƒ‰ì–´")
        st.write(f"ì´ **{len(df)}**ê°œ í‚¤ì›Œë“œ")
        col1, col2 = st.columns(2)
        with col1:
            cat_filter = st.multiselect("ì¹´í…Œê³ ë¦¬ í•„í„°", df["category"].unique().tolist(), default=df["category"].unique().tolist())
        with col2:
            search = st.text_input("í‚¤ì›Œë“œ ê²€ìƒ‰", placeholder="í‚¤ì›Œë“œ ì…ë ¥...")
        df_filtered = df[df["category"].isin(cat_filter)]
        if search:
            df_filtered = df_filtered[df_filtered["keyword"].str.contains(search, case=False, na=False)]
        col_map = {"category": "ì¹´í…Œê³ ë¦¬", "rank": "ìˆœìœ„", "keyword": "í‚¤ì›Œë“œ", "change_trend": "ë³€í™”ì¶”ì´"}
        st.dataframe(df_filtered.rename(columns=col_map), use_container_width=True, hide_index=True)
    else:
        st.warning("trending_keywords.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒë‹¨ 'ğŸ“¥ ë„¤ì´ë²„ íŠ¸ë Œë“œ ìŠ¤í¬ë˜í•‘' ë²„íŠ¼ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

# === íƒ­2: ì‹œì¥ì„± ì ìˆ˜ (coupang_analyzer ê²°ê³¼) ===
with tab2:
    if NICHE_SCORE.exists():
        df = pd.read_csv(NICHE_SCORE, encoding="utf-8-sig")
        st.subheader("ì¿ íŒ¡ ì§„ì… ê°€ëŠ¥ì„± ì ìˆ˜")
        st.write(f"ì´ **{len(df)}**ê°œ í‚¤ì›Œë“œ ë¶„ì„")

        # ìš”ì•½ ì¹´ë“œ
        c1, c2, c3, c4 = st.columns(4)
        with c1:
            st.metric("í‰ê·  ì ìˆ˜", f"{df['opportunity_score'].mean():.1f}")
        with c2:
            high = (df["opportunity_score"] >= 70).sum()
            st.metric("70ì  ì´ìƒ", f"{high}ê°œ")
        with c3:
            st.metric("í‰ê·  ë¡œì¼“ ìˆ˜", f"{df['rocket_count'].mean():.1f}")
        with c4:
            st.metric("í‰ê·  ê°€ê²©ëŒ€", f"{df['avg_price'].mean():,.0f}ì›")

        # ì ìˆ˜ìˆœ ì •ë ¬
        score_min = st.slider("ìµœì†Œ ì§„ì…ì ìˆ˜", 0, 100, 0)
        df_filtered = df[df["opportunity_score"] >= score_min].sort_values("opportunity_score", ascending=False)
        col_map = {
            "category": "ì¹´í…Œê³ ë¦¬", "rank": "ìˆœìœ„", "keyword": "í‚¤ì›Œë“œ", "change_trend": "ë³€í™”ì¶”ì´",
            "rocket_count": "ë¡œì¼“ìˆ˜", "avg_price": "í‰ê· ê°€", "min_price": "ìµœì €ê°€", "max_price": "ìµœê³ ê°€",
            "price_range": "ê°€ê²©í­", "avg_reviews": "í‰ê· ë¦¬ë·°", "opportunity_score": "ì§„ì…ì ìˆ˜",
            "total_products": "ìƒ˜í”Œìˆ˜", "accuracy_rating": "ì‹ ë¢°ë„",
        }
        df_renamed = df_filtered.rename(columns=col_map)
        styled = _style_rocket_zero(df_renamed, "ë¡œì¼“ìˆ˜") if "rocket_count" in df_filtered.columns else df_renamed.style
        price_cols = [c for c in ["avg_price", "min_price", "max_price", "price_range"] if c in df_filtered.columns]
        if price_cols:
            fmt_map = {col_map[c]: "{:,.0f}" for c in price_cols if col_map[c] in df_renamed.columns}
            if fmt_map:
                styled = styled.format(fmt_map)
        st.dataframe(styled, use_container_width=True, hide_index=True)
    else:
        st.warning("niche_score_report.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒë‹¨ 'ğŸ“ˆ ì¿ íŒ¡ ì‹œì¥ì„± ë¶„ì„' ë²„íŠ¼ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

# === íƒ­3: ë‹ˆì¹˜ ë¶„ì„ (niche_analysis ê²°ê³¼) ===
with tab3:
    if NICHE_ANALYSIS.exists():
        df = pd.read_csv(NICHE_ANALYSIS, encoding="utf-8-sig")
        st.subheader("ì¿ íŒ¡ ë‹ˆì¹˜ ë¶„ì„ (ë¡œì¼“/ê°€ê²©/ë¦¬ë·°)")
        st.write(f"ì´ **{len(df)}**ê°œ í‚¤ì›Œë“œ")
        grade_filter = st.multiselect("ë“±ê¸‰ í•„í„°", ["S", "A", "B"], default=["S", "A"])
        df_filtered = df[df["grade"].isin(grade_filter)]
        col_map = {
            "category": "ì¹´í…Œê³ ë¦¬", "rank": "ìˆœìœ„", "keyword": "í‚¤ì›Œë“œ", "change_trend": "ë³€í™”ì¶”ì´",
            "rocket_count": "ë¡œì¼“ìˆ˜", "total_products": "ìƒí’ˆìˆ˜", "avg_price": "í‰ê· ê°€",
            "max_reviews": "ìµœëŒ€ë¦¬ë·°", "grade": "ë“±ê¸‰",
        }
        df_renamed = df_filtered.rename(columns=col_map)
        styled = _style_rocket_zero(df_renamed, "ë¡œì¼“ìˆ˜") if "rocket_count" in df_filtered.columns else df_renamed.style
        if "avg_price" in df_filtered.columns:
            styled = styled.format({"í‰ê· ê°€": "{:,.0f}"})
        st.dataframe(styled, use_container_width=True, hide_index=True)
    else:
        st.warning("niche_analysis.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒë‹¨ 'ğŸ” ì¿ íŒ¡ ë‹ˆì¹˜ ë¶„ì„' ë²„íŠ¼ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

# === íƒ­4: ë‹ˆì¹˜ í…ŒìŠ¤íŠ¸ (ìƒìœ„ 20ê°œ) ===
with tab4:
    if NICHE_TEST.exists():
        df = pd.read_csv(NICHE_TEST, encoding="utf-8-sig")
        st.subheader("ì¿ íŒ¡ ë‹ˆì¹˜ í…ŒìŠ¤íŠ¸ (ìƒìœ„ 20ê°œ)")
        st.write(f"ì´ **{len(df)}**ê°œ í‚¤ì›Œë“œ | ì£¼í™©ìƒ‰ í–‰ = ë¡œì¼“ 0 â†’ ìˆ˜ë™ ê²€ì¦ í•„ìš”")

        # ë‹ˆì¹˜í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½ í‘œ: ì œí’ˆëª… / ì¿ íŒ¡ ìµœì €Â·ìµœê³ Â·í‰ê·  / ë„ë§¤ ê²€ìƒ‰ê²°ê³¼ / ë„ë§¤ê°€(ìµœì €) / ì†Œì‹±ì²˜
        summary_rows = []
        sourcing_df = pd.read_csv(FINAL_SOURCING, encoding="utf-8-sig") if FINAL_SOURCING.exists() else None
        for _, row in df.iterrows():
            kw = row.get("keyword", "")
            c_min = row.get("min_price", None)
            c_max = row.get("max_price", None)
            c_avg = row.get("avg_price", row.get("í‰ê· ê°€", ""))
            if pd.isna(c_min):
                c_min = ""
            if pd.isna(c_max):
                c_max = ""
            if c_min != "" and int(c_min) == 0:
                c_min = ""
            if c_max != "" and int(c_max) == 0:
                c_max = ""
            src_row = None
            if sourcing_df is not None and "í‚¤ì›Œë“œ" in sourcing_df.columns:
                match = sourcing_df[sourcing_df["í‚¤ì›Œë“œ"].astype(str).str.strip() == str(kw).strip()]
                src_row = match.iloc[0] if len(match) else None
            has_sourcing = "ìˆìŒ" if src_row is not None else "ì—†ìŒ"
            wholesale_price = ""
            source_name = ""
            if src_row is not None:
                wholesale_price = src_row.get("ë„ë§¤ê°€(ìµœì €)", "")
                source_name = src_row.get("ìµœì¢… ì†Œì‹±ì²˜", "")
            summary_rows.append({
                "ì œí’ˆëª…": kw,
                "ì¿ íŒ¡ ìµœì €ê°€": c_min,
                "ì¿ íŒ¡ ìµœê³ ê°€": c_max,
                "ì¿ íŒ¡ í‰ê· ê°€": c_avg,
                "ë„ë§¤ ê²€ìƒ‰ê²°ê³¼": has_sourcing,
                "ë„ë§¤ê°€(ìµœì €)": wholesale_price,
                "ì†Œì‹±ì²˜": source_name,
            })
        if summary_rows:
            summary_df = pd.DataFrame(summary_rows)
            def _fmt_price(val):
                if val is None or val == "" or (isinstance(val, float) and pd.isna(val)):
                    return "â€”"
                try:
                    n = int(float(str(val).replace(",", "")))
                    return f"{n:,}" if n else "â€”"
                except (ValueError, TypeError):
                    return str(val) if val else "â€”"
            summary_df["ì¿ íŒ¡ ìµœì €ê°€"] = summary_df["ì¿ íŒ¡ ìµœì €ê°€"].map(_fmt_price)
            summary_df["ì¿ íŒ¡ ìµœê³ ê°€"] = summary_df["ì¿ íŒ¡ ìµœê³ ê°€"].map(_fmt_price)
            summary_df["ì¿ íŒ¡ í‰ê· ê°€"] = summary_df["ì¿ íŒ¡ í‰ê· ê°€"].map(_fmt_price)
            summary_df["ë„ë§¤ê°€(ìµœì €)"] = summary_df["ë„ë§¤ê°€(ìµœì €)"].map(_fmt_price)
            st.caption("ë‹ˆì¹˜í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
            st.dataframe(summary_df, use_container_width=True, hide_index=True)

        grade_filter = st.multiselect("ë“±ê¸‰ í•„í„° ", ["S", "A", "B"], default=["S", "A"], key="grade_filter_test")
        df_filtered = df[df["grade"].isin(grade_filter)]
        col_map = {
            "category": "ì¹´í…Œê³ ë¦¬", "rank": "ìˆœìœ„", "keyword": "í‚¤ì›Œë“œ", "change_trend": "ë³€í™”ì¶”ì´",
            "rocket_count": "ë¡œì¼“ìˆ˜", "total_products": "ìƒí’ˆìˆ˜", "avg_price": "í‰ê· ê°€",
            "max_reviews": "ìµœëŒ€ë¦¬ë·°", "grade": "ë“±ê¸‰",
        }
        df_valid = _add_validation_icon(df_filtered, "rocket_count")
        col_map["_validation"] = "âš ï¸ê²€ì¦"

        col_tbl, col_val = st.columns([3, 1])
        with col_tbl:
            df_renamed = df_valid.rename(columns=col_map)
            styled = _style_rocket_zero(df_renamed, "ë¡œì¼“ìˆ˜") if "rocket_count" in df_valid.columns else df_renamed.style
            if "í‰ê· ê°€" in df_renamed.columns:
                styled = styled.format({"í‰ê· ê°€": "{:,.0f}"})
            st.dataframe(styled, use_container_width=True, hide_index=True)

        with col_val:
            keywords_list = df_filtered["keyword"].dropna().astype(str).tolist()
            selected_kw = st.selectbox("í‚¤ì›Œë“œ ì„ íƒ (ê²€ì¦ ì´ë¯¸ì§€)", [""] + keywords_list, key="kw_select_niche")
            if selected_kw:
                safe_name = "".join(c if c.isalnum() or c in "._-" else "_" for c in selected_kw)
                for p in [DEBUG_SCREENSHOTS / f"{safe_name}.png", DEBUG_SCREENSHOTS / f"{selected_kw}.png", BASE / "debug_screenshot.png"]:
                    if p.exists():
                        st.image(str(p), caption=f"ê²€ì¦: {selected_kw}", use_container_width=True)
                        break
                else:
                    st.caption("ê²€ì¦ ìŠ¤í¬ë¦°ìƒ· ì—†ìŒ (debug_screenshots/ í´ë”)")

                # ìˆ˜ë™ ê²€ì¦ ì¬ì¡°ì‚¬: ì‹œê° ìŠ¤í¬ë˜í¼ë¡œ í•´ë‹¹ í‚¤ì›Œë“œë§Œ ì¬ë¶„ì„ â†’ niche_test.csv, DB ë°˜ì˜
                if st.button("ğŸ” ìˆ˜ë™ ê²€ì¦ ì¬ì¡°ì‚¬", key="btn_verify_rescan"):
                    sys.path.insert(0, str(BASE))
                    try:
                        from coupang_visual_fallback import scrape_and_save
                        from core.database import update_product_rocket_count
                        fallback = scrape_and_save(selected_kw)
                        if fallback.get("error"):
                            st.error(f"ì‹œê° ê²€ì¦ ì‹¤íŒ¨: {fallback['error']} (ì¿ íŒ¡ ì°¨ë‹¨ ì‹œ ë°œìƒ)")
                        else:
                            new_rocket = fallback.get("rocket_count", 0)
                            # niche_test.csv í•´ë‹¹ í–‰ ì—…ë°ì´íŠ¸
                            ntf = pd.read_csv(NICHE_TEST, encoding="utf-8-sig")
                            mask = ntf["keyword"] == selected_kw
                            if mask.any():
                                ntf.loc[mask, "rocket_count"] = new_rocket
                                ntf.loc[mask, "verification_needed"] = ""
                                grade = "S" if new_rocket < 5 else ("A" if new_rocket <= 10 else "B")
                                ntf.loc[mask, "grade"] = grade
                                ntf.to_csv(NICHE_TEST, index=False, encoding="utf-8-sig")
                            # DB ë°˜ì˜
                            opp = 80 - new_rocket * 5 if new_rocket < 15 else 10
                            updated = update_product_rocket_count(selected_kw, new_rocket, opp)
                            st.success(f"ì¬ì¡°ì‚¬ ì™„ë£Œ: ë¡œì¼“ {new_rocket}ê°œ | DB ë°˜ì˜: {'ë¨' if updated else 'í•´ë‹¹ ì—†ìŒ'}")
                            st.rerun()
                    except Exception as e:
                        st.error(f"ì¬ì¡°ì‚¬ ì˜¤ë¥˜: {e}")

                with st.expander(f"ğŸ“Š {selected_kw} ìƒì„¸ ë¶„ì„"):
                    if st.button("3ë…„ íŠ¸ë Œë“œ + ê²€ìƒ‰ëŸ‰ ì¡°íšŒ", key=f"fetch_{selected_kw}"):
                        sys.path.insert(0, str(BASE))
                        from dashboard_helpers import fetch_trend_3year, fetch_search_volume
                        periods, ratios = fetch_trend_3year(selected_kw)
                        vol = fetch_search_volume(selected_kw)
                        st.session_state["keyword_detail"] = {"kw": selected_kw, "periods": periods, "ratios": ratios, "vol": vol}
                    detail = st.session_state.get("keyword_detail", {})
                    if detail.get("kw") == selected_kw and (detail.get("periods") or detail.get("vol")):
                        if detail.get("periods") and detail.get("ratios") and HAS_PLOTLY:
                            fig = go.Figure()
                            fig.add_trace(go.Scatter(x=detail["periods"], y=detail["ratios"], mode="lines+markers", name="ê²€ìƒ‰ëŸ‰(ìƒëŒ€)"))
                            fig.update_layout(title=f"'{selected_kw}' 3ë…„ íŠ¸ë Œë“œ", xaxis_title="ì›”", height=250)
                            st.plotly_chart(fig, use_container_width=True)
                        if detail.get("vol") is not None:
                            st.metric("ì‹¤ì‹œê°„ ê²€ìƒ‰ëŸ‰ (ì›”)", f"{int(detail['vol']):,}")
                    elif st.session_state.get("keyword_detail", {}).get("kw") == selected_kw and not detail.get("periods") and detail.get("vol") is None:
                        st.info("API í‚¤ í™•ì¸ í•„ìš” (config.py)")
                    if not HAS_PLOTLY:
                        st.caption("pip install plotly")
    else:
        st.warning("niche_test.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒë‹¨ 'ğŸ§ª ë‹ˆì¹˜ í…ŒìŠ¤íŠ¸ (ìƒìœ„ 20ê°œ)' ë²„íŠ¼ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

# === íƒ­5: ê²€ìƒ‰ëŸ‰ (niche_with_volume / trending_with_volume) ===
with tab5:
    vol_df = None
    vol_title = ""
    if NICHE_WITH_VOLUME.exists():
        vol_df = pd.read_csv(NICHE_WITH_VOLUME, encoding="utf-8-sig")
        vol_title = "ê²€ìƒ‰ëŸ‰ í¬í•¨ ë‹ˆì¹˜ ê²°ê³¼ (niche_with_volume.csv)"
    elif TRENDING_WITH_VOLUME.exists():
        vol_df = pd.read_csv(TRENDING_WITH_VOLUME, encoding="utf-8-sig")
        vol_title = "ê²€ìƒ‰ëŸ‰ í¬í•¨ íŠ¸ë Œë“œ (trending_with_volume.csv)"
    if vol_df is not None and not vol_df.empty:
        st.subheader(vol_title)
        st.write(f"ì´ **{len(vol_df)}**ê°œ í‚¤ì›Œë“œ (ê²€ìƒ‰ëŸ‰â†‘ ë¡œì¼“â†“ ìˆœ ì •ë ¬)")
        st.caption("niche_test.csvì— ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  APIë¡œ ê²€ìƒ‰ëŸ‰ ì¶”ê°€. ìƒë‹¨ 'ğŸ“Š ê²€ìƒ‰ëŸ‰ ìˆ˜ì§‘' ë²„íŠ¼ìœ¼ë¡œ ìƒì„±.")
        col_map_vol = {c: c for c in vol_df.columns}
        if "keyword" in vol_df.columns:
            col_map_vol["keyword"] = "í‚¤ì›Œë“œ"
        if "rocket_count" in vol_df.columns:
            col_map_vol["rocket_count"] = "ë¡œì¼“ìˆ˜"
        vol_display = vol_df.rename(columns=col_map_vol)
        st.dataframe(vol_display, use_container_width=True, hide_index=True)
    else:
        st.warning("niche_with_volume.csvê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € 'ğŸ§ª ë‹ˆì¹˜ í…ŒìŠ¤íŠ¸'ë¥¼ ì‹¤í–‰í•œ ë’¤ 'ğŸ“Š ê²€ìƒ‰ëŸ‰ ìˆ˜ì§‘' ë²„íŠ¼ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

# === íƒ­6: ì†Œì‹± ë¦¬ìŠ¤íŠ¸ (final_sourcing_list) ===
with tab6:
    if FINAL_SOURCING.exists():
        # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼ì„ ë¨¼ì € ë‘ì–´ í´ë¦­ ì‹œ ë°”ë¡œ rerun í›„ ì•„ë˜ì—ì„œ íŒŒì¼ ì¬ë¡œë“œ
        row1_col1, row1_col2 = st.columns([4, 1])
        with row1_col2:
            if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", key="sourcing_refresh", help="ìµœì‹  final_sourcing_list.csv ë‹¤ì‹œ ë¶ˆëŸ¬ì˜¤ê¸°"):
                st.rerun()
        # ë§¤ ë Œë”ë§ˆë‹¤ íŒŒì¼ì„ ë””ìŠ¤í¬ì—ì„œ ë‹¤ì‹œ ì½ìŒ (ìºì‹œ ì—†ìŒ)
        csv_path = Path(FINAL_SOURCING)
        df = pd.read_csv(csv_path, encoding="utf-8-sig")
        with row1_col1:
            st.subheader("ìµœì¢… ì†Œì‹± ë¦¬ìŠ¤íŠ¸ (ìµœì¢… ìˆœë§ˆì§„ 15% ì´ìƒ)")
            st.caption("ê´‘ê³ ë¹„(15%)Â·ìˆ˜ìˆ˜ë£ŒÂ·ë°°ì†¡ë¹„Â·ë¶€ê°€ì„¸ ë°˜ì˜ í›„ ìˆœì´ìµ ê¸°ì¤€ (ê´‘ê³ ë¹„ ì œì™¸ í›„ ìˆœì´ìµ)")
            st.write(f"ì´ **{len(df)}**ê±´")
            try:
                mtime = csv_path.stat().st_mtime
                mtime_str = datetime.fromtimestamp(mtime).strftime("%Y-%m-%d %H:%M:%S")
                st.caption(f"ğŸ“ CSV íŒŒì¼ ìˆ˜ì • ì‹œê°: **{mtime_str}** (ì´ ì‹œê°ì— ë„ë§¤ ê²€ìƒ‰ì´ ì €ì¥í•œ ê²°ê³¼ì…ë‹ˆë‹¤)")
            except Exception:
                pass
        st.caption("ğŸ’¡ 'ìƒˆë¡œê³ ì¹¨' í´ë¦­ ì‹œ ìœ„ íŒŒì¼ ìˆ˜ì • ì‹œê°ì´ ë°”ë€Œì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. ë°ì´í„°ê°€ ê·¸ëŒ€ë¡œë©´ ë„ë§¤ ê²€ìƒ‰ì„ ë‹¤ì‹œ ì‹¤í–‰í•œ ë’¤ ìƒˆë¡œê³ ì¹¨í•˜ì„¸ìš”.")
        with st.expander("ğŸ“Œ í•œ ë‹¬ ê²€ìƒ‰ëŸ‰Â·íƒœê·¸Â·ë„ë§¤ì²˜ë§í¬ê°€ ë¹„ì–´ ìˆëŠ” ì´ìœ "):
            st.markdown("""
            - **í•œ ë‹¬ ê²€ìƒ‰ëŸ‰**  
              ë„ë§¤ ê²€ìƒ‰ ì‹œ ìˆœë§ˆì§„ 15% ì´ìƒì¸ í‚¤ì›Œë“œì— ëŒ€í•´ **ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  API**ë¡œ ì¡°íšŒí•©ë‹ˆë‹¤.  
              ë¹„ì–´ ìˆìœ¼ë©´ â†’ `config.py`ì˜ **CUSTOMER_ID, SECRET_KEY, ACCESS_LICENSE** í™•ì¸, [ë„¤ì´ë²„ ê²€ìƒ‰ê´‘ê³  API ì‚¬ìš© ì‹ ì²­](https://manage.searchad.naver.com) ìŠ¹ì¸ ì—¬ë¶€ í™•ì¸. ë„ë§¤ ê²€ìƒ‰ ì‹¤í–‰ ì‹œ í„°ë¯¸ë„ì— `[ì‹¬í™”] í•œ ë‹¬ ê²€ìƒ‰ëŸ‰: NíšŒ`ê°€ ì•ˆ ë³´ì´ë©´ API í˜¸ì¶œì´ ì‹¤íŒ¨í•œ ê²ƒì…ë‹ˆë‹¤.

            - **íƒœê·¸**  
              **í•œ ë‹¬ ê²€ìƒ‰ëŸ‰ 5,000íšŒ ì´ìƒ** ì´ë©´ì„œ **ìˆœë§ˆì§„ 15% ì´ìƒ**ì¼ ë•Œë§Œ `[ê°•ë ¥ ì¶”ì²œ]`ì´ ë¶™ìŠµë‹ˆë‹¤.  
              í•œ ë‹¬ ê²€ìƒ‰ëŸ‰ì´ ë¹„ì–´ ìˆìœ¼ë©´ íƒœê·¸ë„ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.

            - **ë„ë§¤ì²˜ë§í¬**  
              ë„ë§¤ê¾¹/ì˜¤ë„ˆí´ëœì—ì„œ ìƒí’ˆ **ìƒì„¸ í˜ì´ì§€ URL**ì„ ì°¾ì§€ ëª»í•˜ë©´ `ê²€ìƒ‰ê²°ê³¼ì—†ìŒ`ìœ¼ë¡œ ì €ì¥ë©ë‹ˆë‹¤.  
              ì‚¬ì´íŠ¸ êµ¬ì¡° ë³€ê²½Â·ë¡œê·¸ì¸ í•„ìš”Â·ì…€ë ‰í„° ë¶ˆì¼ì¹˜ ì‹œ ë§í¬ê°€ ìˆ˜ì§‘ë˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. **ë„ë§¤ ê²€ìƒ‰**ì„ ë‹¤ì‹œ ì‹¤í–‰í•´ë„ ê³„ì† ë¹„ì–´ ìˆìœ¼ë©´ ë„ë§¤ ì‚¬ì´íŠ¸ HTML êµ¬ì¡°ë¥¼ ì ê²€í•´ì•¼ í•©ë‹ˆë‹¤.
            """)
        df = df.copy()
        # ì—´ê¸°: http(s)ì¸ ê²½ìš°ë§Œ ë§í¬ë¡œ ì‚¬ìš©. ë„ë§¤ì²˜ë§í¬ëŠ” í•­ìƒ í…ìŠ¤íŠ¸ë¡œ í‘œì‹œ
        if "ë„ë§¤ì²˜ë§í¬" in df.columns:
            s = df["ë„ë§¤ì²˜ë§í¬"].astype(str).str.strip()
            valid_url = s.str.startswith("http")
            df["ì—´ê¸°"] = df["ë„ë§¤ì²˜ë§í¬"].where(valid_url, pd.NA)
        # NaN â†’ ë¹ˆ ì¹¸ í‘œì‹œ ("None" ì•ˆ ë‚˜ì˜¤ê²Œ)
        for col in ["í•œ ë‹¬ ê²€ìƒ‰ëŸ‰", "íƒœê·¸"]:
            if col in df.columns:
                df[col] = df[col].fillna("").astype(str).replace({"None": "", "nan": ""})
        if "ì—´ê¸°" in df.columns:
            df["ì—´ê¸°"] = df["ì—´ê¸°"].fillna("")
        col_config = {}
        if "ë„ë§¤ì²˜ë§í¬" in df.columns:
            col_config["ë„ë§¤ì²˜ë§í¬"] = st.column_config.TextColumn("ë„ë§¤ì²˜ë§í¬", help="ë„ë§¤ ì‚¬ì´íŠ¸ ì£¼ì†Œ ë˜ëŠ” ê²€ìƒ‰ê²°ê³¼ì—†ìŒ")
        if "ì—´ê¸°" in df.columns:
            col_config["ì—´ê¸°"] = st.column_config.LinkColumn("ì—´ê¸°", display_text="ì—´ê¸°", help="URLì´ ìˆì„ ë•Œë§Œ í´ë¦­ ê°€ëŠ¥ (ì—†ìœ¼ë©´ ë¹ˆ ì¹¸)")
        if "ì¿ íŒ¡ê°€" in df.columns:
            col_config["ì¿ íŒ¡ê°€"] = st.column_config.NumberColumn("ì¿ íŒ¡ê°€", format="%dì›")
        if "ë„ë§¤ê°€(ìµœì €)" in df.columns:
            col_config["ë„ë§¤ê°€(ìµœì €)"] = st.column_config.NumberColumn("ë„ë§¤ê°€(ìµœì €)", format="%dì›")
        if "ì˜ˆìƒ ìˆœì´ìµ" in df.columns:
            col_config["ì˜ˆìƒ ìˆœì´ìµ"] = st.column_config.NumberColumn("ì˜ˆìƒ ìˆœì´ìµ", format="%dì›")
        if "ìµœì¢… ìˆœë§ˆì§„ì•¡" in df.columns:
            col_config["ìµœì¢… ìˆœë§ˆì§„ì•¡"] = st.column_config.NumberColumn(
                "ìµœì¢… ìˆœë§ˆì§„ì•¡ (ê´‘ê³ ë¹„ ì œì™¸ ìˆœì´ìµ)", format="%dì›",
                help="ê´‘ê³ ë¹„Â·ìˆ˜ìˆ˜ë£ŒÂ·ë°°ì†¡ë¹„Â·ë¶€ê°€ì„¸ ì°¨ê° í›„ ìˆœì´ìµ"
            )
        if "ìµœì¢… ìˆœë§ˆì§„ìœ¨" in df.columns:
            col_config["ìµœì¢… ìˆœë§ˆì§„ìœ¨"] = st.column_config.TextColumn("ìµœì¢… ìˆœë§ˆì§„ìœ¨")
        if "ìˆœë§ˆì§„ìœ¨" in df.columns:
            col_config["ìˆœë§ˆì§„ìœ¨"] = st.column_config.TextColumn("ìˆœë§ˆì§„ìœ¨")
        if "ìµœì¢… ì†Œì‹±ì²˜" in df.columns:
            col_config["ìµœì¢… ì†Œì‹±ì²˜"] = st.column_config.TextColumn("ìµœì¢… ì†Œì‹±ì²˜", help="ë„ë§¤ê¾¹/ì˜¤ë„ˆí´ëœ ì¤‘ ë” ì €ë ´í•œ ê³³")
        st.dataframe(df, use_container_width=True, hide_index=True, column_config=col_config or None)
    else:
        st.warning("final_sourcing_list.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒë‹¨ 'ğŸª ë„ë§¤ ê²€ìƒ‰ (ì†Œì‹± ë¦¬ìŠ¤íŠ¸)' ë²„íŠ¼ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

# === íƒ­7: ì‹ ë¢°ë„ ë¦¬í¬íŠ¸ ===
with tab7:
    if MARKET_CREDIBILITY.exists():
        df = pd.read_csv(MARKET_CREDIBILITY, encoding="utf-8-sig")
        st.subheader("ë°ì´í„° ê¸°ë°˜ ì§„ì… ì‹ ë¢°ë„ ë¦¬í¬íŠ¸")
        st.write(f"ì´ **{len(df)}**ê±´")
        st.caption("ì´ê±´ ì§€ê¸ˆ ì‚¬ì•¼ í•´(ì‹œì¦Œ) | ì´ê±´ 1ë…„ ë‚´ë‚´ íŒ”ë ¤(ìŠ¤í…Œë””) | ì´ê±´ í•¨ì •(í•˜ë½ì„¸)")
        rec_filter = st.multiselect("ì§„ì…ê¶Œì¥ í•„í„°", df["ì§„ì…ê¶Œì¥ì—¬ë¶€"].unique().tolist(), default=df["ì§„ì…ê¶Œì¥ì—¬ë¶€"].unique().tolist(), key="rec_filter")
        df_filtered = df[df["ì§„ì…ê¶Œì¥ì—¬ë¶€"].isin(rec_filter)]
        st.dataframe(df_filtered, use_container_width=True, hide_index=True)
        charts_dir = BASE / "credibility_charts"
        if charts_dir.exists():
            imgs = list(charts_dir.glob("*.png"))
            if imgs:
                st.subheader("ìƒìœ„ 5ê°œ ê²€ìƒ‰ëŸ‰ ì¶”ì´")
                for p in sorted(imgs)[:5]:
                    st.image(str(p), caption=p.stem, use_container_width=True)
    else:
        st.warning("market_credibility_report.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒë‹¨ 'ğŸ“‹ ì‹ ë¢°ë„ ë¦¬í¬íŠ¸' ë²„íŠ¼ì„ ì‹¤í–‰í•˜ì„¸ìš”. (config.pyì— ë„¤ì´ë²„ ë°ì´í„°ë© API í‚¤ í•„ìš”)")

# === íƒ­8: ì‚¬ì… ì í•© ===
with tab8:
    if LIGHT_WEIGHT.exists():
        df = pd.read_excel(LIGHT_WEIGHT, engine="openpyxl")
        st.subheader("ì‚¬ì… ì í•©ì„± í•„í„° (light_weight_niche.xlsx)")
        st.write(f"ì´ **{len(df)}**ê±´ (ê°€ê²© 1.5~6ë§Œì›, ë¶€í”¼ í° í’ˆëª© ì œì™¸, ë¬¶ìŒ ê°€ì‚°)")
        price_cols = [c for c in ["í‰ê· ê°€", "avg_price"] if c in df.columns]
        if price_cols:
            df_display = df.copy()
            try:
                df_display = df_display.style.format({price_cols[0]: "{:,.0f}"})
            except Exception:
                pass
            st.dataframe(df_display, use_container_width=True, hide_index=True)
        else:
            st.dataframe(df, use_container_width=True, hide_index=True)
    else:
        st.warning("light_weight_niche.xlsx íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒë‹¨ 'ğŸ“¦ ì‚¬ì… ì í•©ì„± í•„í„°' ë²„íŠ¼ì„ ì‹¤í–‰í•˜ì„¸ìš”.")

# === íƒ­9: DB (SQLite) ===
with tab9:
    if DB_PATH.exists():
        try:
            import sqlite3
            conn = sqlite3.connect(str(DB_PATH))
            # Products í…Œì´ë¸” ìš°ì„  (ë§ˆìŠ¤í„° ì‹œìŠ¤í…œ)
            try:
                df = pd.read_sql_query("SELECT keyword, category, naver_rank, naver_search_vol, coupang_avg_price, rocket_count, opportunity_score, updated_at FROM Products ORDER BY updated_at DESC LIMIT 200", conn)
                col_map = {"keyword": "í‚¤ì›Œë“œ", "category": "ì¹´í…Œê³ ë¦¬", "naver_rank": "ë„¤ì´ë²„ìˆœìœ„", "naver_search_vol": "ë„¤ì´ë²„ê²€ìƒ‰ëŸ‰", "coupang_avg_price": "í‰ê· ê°€", "rocket_count": "ë¡œì¼“ìˆ˜", "opportunity_score": "ì§„ì…ì ìˆ˜", "updated_at": "ìˆ˜ì •ì¼ì‹œ"}
            except Exception:
                df = pd.read_sql_query("SELECT keyword, category, collected_at, naver_rank, coupang_rocket_count, coupang_avg_price, consistency_score, validation_status FROM keyword_data ORDER BY collected_at DESC LIMIT 200", conn)
                col_map = {"keyword": "í‚¤ì›Œë“œ", "category": "ì¹´í…Œê³ ë¦¬", "collected_at": "ìˆ˜ì§‘ì¼ì‹œ", "naver_rank": "ë„¤ì´ë²„ìˆœìœ„", "coupang_rocket_count": "ë¡œì¼“ìˆ˜", "coupang_avg_price": "í‰ê· ê°€", "consistency_score": "ì¼ê´€ì„±ì ìˆ˜", "validation_status": "ê²€ì¦ìƒíƒœ"}
            conn.close()
            st.subheader("SQLite DB (Products)")
            st.write(f"ìµœê·¼ **{len(df)}**ê±´")
            df_display = df.rename(columns=col_map)
            fmt_cols = {c: "{:,.0f}" for c in ["í‰ê· ê°€"] if c in df_display.columns}
            fmt_cols.update({c: "{:.1f}" for c in ["ì¼ê´€ì„±ì ìˆ˜", "ì§„ì…ì ìˆ˜", "ë„¤ì´ë²„ê²€ìƒ‰ëŸ‰"] if c in df_display.columns})
            if fmt_cols:
                df_display = df_display.style.format(fmt_cols, na_rep="-")
            st.dataframe(df_display, use_container_width=True, hide_index=True)
        except Exception as e:
            st.error(f"DB ì¡°íšŒ ì˜¤ë¥˜: {e}")
    else:
        st.warning("coupang_gross.db ì—†ìŒ. ìƒë‹¨ 'ğŸ”„ ë§ˆìŠ¤í„° íŒŒì´í”„ë¼ì¸' ì‹¤í–‰ í›„ ìƒì„±ë©ë‹ˆë‹¤.")

# === íƒ­10: ì‹œì¦Œ í—Œí„° ===
with tab10:
    if SEASONAL_HUNTER.exists():
        df = pd.read_csv(SEASONAL_HUNTER, encoding="utf-8-sig")
        st.subheader("ì‹œì¦Œ í—Œí„° - ë°˜ë³µ ì‹œì¦Œ í‚¤ì›Œë“œ")
        st.write(f"ì´ **{len(df)}**ê°œ í‚¤ì›Œë“œ ë¶„ì„")
        st.caption("ë§¤ë…„ íŠ¹ì • ì›”ì—ë§Œ ê²€ìƒ‰ëŸ‰ì´ í­ë“±í•˜ëŠ” í‚¤ì›Œë“œ. ì•ìœ¼ë¡œ 2ê°œì›” ë‚´ í­ë“± ì˜ˆì •ì„ ì„ ì œì ìœ¼ë¡œ í™•ì¸í•˜ì„¸ìš”.")
        upcoming_filter = st.radio("2ê°œì›” ë‚´ í­ë“± ì˜ˆì •ë§Œ", ["ì „ì²´", "ì˜ˆì •ë§Œ"], horizontal=True, key="seasonal_filter")
        if upcoming_filter == "ì˜ˆì •ë§Œ":
            df_filtered = df[df["2ê°œì›” ë‚´ í­ë“± ì˜ˆì •"] == "ì˜ˆ"]
        else:
            df_filtered = df
        st.dataframe(df_filtered, use_container_width=True, hide_index=True)
        if SEASONAL_CHARTS.exists():
            imgs = list(SEASONAL_CHARTS.glob("*.png"))
            if imgs:
                st.subheader("3ë…„ì¹˜ ê²€ìƒ‰ëŸ‰ ì¶”ì´ ì°¨íŠ¸")
                for p in sorted(imgs)[:5]:
                    st.image(str(p), caption=p.stem.replace("_3year", ""), use_container_width=True)
    else:
        st.warning("seasonal_hunter_report.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìƒë‹¨ 'ğŸ“… ì‹œì¦Œ í—Œí„°' ë²„íŠ¼ì„ ì‹¤í–‰í•˜ì„¸ìš”. (config.pyì— ë„¤ì´ë²„ ë°ì´í„°ë© API í‚¤ í•„ìš”)")

# === íƒ­11: ìš”ì•½ ===
with tab11:
    st.subheader("ğŸ“‹ ì‹¤í–‰ ê°€ì´ë“œ")
    st.markdown("""
    | ìˆœì„œ | ìƒë‹¨ ë²„íŠ¼ | ê²°ê³¼ |
    |------|-----------|------|
    | 1 | ğŸ“¥ ë„¤ì´ë²„ íŠ¸ë Œë“œ ìŠ¤í¬ë˜í•‘ | trending_keywords.csv |
    | 2 | ğŸ“ˆ ì¿ íŒ¡ ì‹œì¥ì„± ë¶„ì„ | niche_score_report.csv |
    | 3 | ğŸ” ì¿ íŒ¡ ë‹ˆì¹˜ ë¶„ì„ | niche_analysis.csv |
    | 4 | ğŸ§ª ë‹ˆì¹˜ í…ŒìŠ¤íŠ¸ (ìƒìœ„ 20ê°œ) | niche_test.csv |
    | 5 | ğŸ“Š ê²€ìƒ‰ëŸ‰ ìˆ˜ì§‘ | niche_with_volume.csv |
    | 6 | ğŸª ë„ë§¤ ê²€ìƒ‰ (ì†Œì‹± ë¦¬ìŠ¤íŠ¸) | final_sourcing_list.csv |
    | 7 | ğŸ“‹ ì‹ ë¢°ë„ ë¦¬í¬íŠ¸ | market_credibility_report.csv |
    | 8 | ğŸ“¦ ì‚¬ì… ì í•©ì„± í•„í„° | light_weight_niche.xlsx |
    | 9 | ğŸ“… ì‹œì¦Œ í—Œí„° | seasonal_hunter_report.csv |
    | 10 | ğŸ”„ ë§ˆìŠ¤í„° íŒŒì´í”„ë¼ì¸ | coupang_gross.db (Products) |
    """)
    st.info("ëª¨ë“  ì‘ì—…ì€ ìƒë‹¨ ë²„íŠ¼ì—ì„œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨(F5)í•˜ë©´ ìµœì‹  CSV ë°ì´í„°ê°€ ë°˜ì˜ë©ë‹ˆë‹¤.")
    st.caption("ğŸ’¡ Cursor í„°ë¯¸ë„ì—ì„œ í•œê¸€ ê²½ë¡œ ë•Œë¬¸ì— ì˜¤ë¥˜ê°€ ë‚˜ë©´: ëŒ€ì‹œë³´ë“œ ë²„íŠ¼ìœ¼ë¡œ ì‹¤í–‰í•˜ê±°ë‚˜, í´ë”ì—ì„œ run_web.bat / run_niche_test.bat ë“±ì„ ë”ë¸”í´ë¦­í•´ì„œ ì‹¤í–‰í•˜ì„¸ìš”.")

# === ì‹¤í–‰ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë° (í•˜ë‹¨) ===
st.divider()
with st.expander("ğŸ“œ ì‹¤í–‰ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë°", expanded=False):
    if "last_output" in st.session_state:
        st.caption("ë§ˆì§€ë§‰ ì‹¤í–‰ ê²°ê³¼")
        st.text_area("stdout", st.session_state["last_output"], height=200, disabled=True, key="log_area")
    log_path = BASE / "logs" / "dashboard_run.log"
    if log_path.exists():
        try:
            with open(log_path, "r", encoding="utf-8", errors="replace") as f:
                lines = f.readlines()
            tail = "".join(lines[-100:]) if len(lines) > 100 else "".join(lines)
            st.caption("ë¡œê·¸ íŒŒì¼ (logs/dashboard_run.log ìµœê·¼ 100ì¤„)")
            st.text_area("dashboard_run.log", tail, height=150, disabled=True, key="log_file_area")
        except Exception as e:
            st.caption(f"ë¡œê·¸ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
